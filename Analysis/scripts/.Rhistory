summarise(across(all_of(columns_to_normalize), list(mean = ~ mean(.x, na.rm = TRUE), sd = ~ sd(.x, na.rm = TRUE)), .names = "{.col}_{.fn}"))
colnames(data_stats)
# Normalize the values
data <- data %>%
left_join(data_stats, by = c("language", "participant")) %>%
mutate(across(all_of(columns_to_normalize),
list(norm = ~ (. - get(paste0(cur_column(), "_mean"))) / get(paste0(cur_column(), "_sd"))),
.names = "{.col}_norm")) %>%
select(-pitch_median_mean, -pitch_median_sd,
-pitch_sd_mean, -pitch_sd_sd,
-f0_slope_mean, -f0_slope_sd,
-f1_freq_median_mean, -f1_freq_median_sd,
-f2_freq_median_mean, -f2_freq_median_sd) # Optional: remove intermediate mean and sd columns
View(data)
colnames(data)
# Sort columns in the specified order
data <- data %>%
select(
fileName, language, participant, itemType, itemNum, focus, annotationNum,
word, syllText, percProm, duration, duration_noSilence, ampl_median,
ampl_noSilence_median, env_slope, pitch_median, pitch_median_norm, pitch_sd,
pitch_sd_norm, f0_slope, f0_slope_norm, f1_freq_median, f1_freq_median_norm,
f2_freq_median, f2_freq_median_norm, specCentroid_median, entropy_median,
HNR_median, amEnvDep_median, fmDep_median
)
rm(data_stats)
# Update targets
targets <- data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) & syllText != "")
write.csv(targets, file = paste0(datasets, "targets.csv"), row.names = FALSE)
# Combined process to find "pre" and "post" syllables
data_prepost <- data %>%
# First, find rows that do not match the initial exclusion criteria
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE)) %>%
## PRE - Step 1
# Create a new data frame for finding the corresponding "pre" syllables for annotationNum - 1
mutate(annotationNumTarget = annotationNum - 1) %>%
# Join data with itself based on relevant columns
left_join(data, by = c("language", "participant", "itemType", "itemNum", "annotationNumTarget" = "annotationNum"), suffix = c("", ".pre1")) %>%
# Modify the joined columns to be NA where syllText.pre1 does not contain "pre"
mutate(across(ends_with(".pre1"), ~ if_else(grepl("pre", syllText.pre1), ., NA), .names = "{.col}")) %>%
## PRE - Step 2
# Create a new data frame for finding the corresponding "pre" syllables for annotationNum - 2
mutate(annotationNumTarget = annotationNum - 2) %>%
# Join data with itself based on relevant columns
left_join(data, by = c("language", "participant", "itemType", "itemNum", "annotationNumTarget" = "annotationNum"), suffix = c("", ".pre2")) %>%
# Modify the joined columns to be NA where syllText.pre2 does not contain "pre"
mutate(across(ends_with(".pre2"), ~ if_else(grepl("pre", syllText.pre2), ., NA), .names = "{.col}")) %>%
# Combine the results of both pre steps, keeping only one set of pre columns
mutate(
across(ends_with(".pre2"), ~ if_else(!is.na(.), ., get(sub(".pre2$", ".pre1", cur_column()))), .names = "{.col}")
) %>%
select(-ends_with(".pre1")) %>%
rename_with(~ sub("\\.pre2$", "Pre", .), ends_with(".pre2")) %>%
## POST
# Create a new data frame for finding the corresponding "post" syllables
mutate(annotationNumTarget = annotationNum + 1) %>%
# Join data with itself based on relevant columns
left_join(data, by = c("language", "participant", "itemType", "itemNum", "annotationNumTarget" = "annotationNum"), suffix = c("", ".post")) %>%
# Modify the joined columns to be NA where syllText.post does not contain "post"
mutate(across(ends_with(".post"), ~ if_else(grepl("post", syllText.post), ., NA), .names = "{.col}")) %>%
## Ensure all target syllables are included
right_join(data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE)),
by = c("fileName", "annotationNum", "language", "participant", "itemType", "itemNum")) %>%
# Dynamically rename columns that end with .post to end with Post
rename_with(~ sub("\\.post$", "Post", .), ends_with(".post")) %>%
# Remove redundant columns
select(-ends_with(".y")) %>%
# Final renaming to remove .x and ensure column uniqueness
rename_with(~ sub("\\.x$", "", .), ends_with(".x")) %>%
# Remove unnecessary columns
select(-fileNamePre, -focusPre, -wordPre, -fileNamePost, -focusPost, -wordPost, -percPromPost, -percPromPre) %>%
# Sort columns so that "percProm" comes after "syllText"
select(fileName, language, participant, itemType, itemNum, focus, annotationNum, word, syllText, percProm,
everything())
# Find the missing fileNames in data_prepost compared to targets
#missing_from_prepost <- anti_join(data_prepost, targets, by = "fileName")
write.csv(data, file = paste0(datasets, "data_cleaned.csv"), row.names = FALSE)
write.csv(data_prepost, file = paste0(datasets, "data_prepost.csv"), row.names = FALSE)
# Normalized
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = pitch_sd_norm, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f0 (normalized sd)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
# Raw
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = pitch_sd, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f0 (raw sd)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
# Normalized
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = pitch_sd_norm, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f0 (normalized sd)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_pitch_sd_norm.pdf"), plot = last_plot(), width = 6, height = 4)
# Normalized
targets %>%
group_by(language, percProm) %>%
summarize(avg_f0_slope = mean(f0_slope_norm, na.rm = TRUE))
# Raw
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f0_slope_norm, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f0 slope (normalized)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f0_slope_norm.pdf"), plot = last_plot(), width = 6, height = 4)
# Raw
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f0_slope, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f0 slope (raw)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f0_slope.pdf"), plot = last_plot(), width = 6, height = 4)
# Normalized
targets %>%
group_by(language, percProm) %>%
summarize(avg_f1_freq_median = mean(f1_freq_median_norm, na.rm = TRUE))
# Raw
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f1_freq_median, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f1 (raw medians)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f1_freq_median_raw.pdf"), plot = last_plot(), width = 6, height = 4)
# Normalized
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f1_freq_median_norm, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f1 (normalized medians)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f1_freq_median_norm.pdf"), plot = last_plot(), width = 6, height = 4)
# Normalized
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f2_freq_median_norm, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f2 (normalized medians)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f2_freq_median_norm.pdf"), plot = last_plot(), width = 6, height = 4)
# Raw
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f2_freq_median, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f2 (raw medians)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f2_freq_median_raw.pdf"), plot = last_plot(), width = 6, height = 4)
# Normalized
ggplot(targets %>% filter(!is.na(percProm)), aes(x = language, y = f2_freq_median_norm, fill = as.factor(percProm))) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
#title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "f2 (normalized medians)",
fill = "Prosodic prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggsave(filename = paste0(plots, "prominence_f2_freq_median_norm.pdf"), plot = last_plot(), width = 6, height = 4)
data_long <- data_prepost %>%
select(fileName, language, itemType, focus, annotationNum,
starts_with("pitch_"), starts_with("env_"), starts_with("duration"),
starts_with("ampl_"), starts_with("f0_"), starts_with("f1_freq_"),
starts_with("f2_freq_"), starts_with("specCentroid_"),
starts_with("entropy_"), starts_with("HNR_"), starts_with("amEnvDep_"),
starts_with("fmDep_")) %>%
pivot_longer(cols = -c(fileName, language, itemType, focus, annotationNum),
names_to = "variable",
values_to = "value") %>%
mutate(
phase = case_when(
grepl("Pre$", variable) ~ "pre",
grepl("Post$", variable) ~ "post",
TRUE ~ "target"
),
# Remove suffixes from variable names for a cleaner look
variable = gsub("Pre|Post", "", variable)
)
# Correct the phase factor levels
data_long$phase <- factor(data_long$phase, levels = c("pre", "target", "post"))
# Get unique languages and variables
languages <- unique(data_long$language)
variables <- unique(data_long$variable)
# Without lines
for (var in variables) {
for (lang in languages) {
# Filter data_long for the current language and variable
data_filtered <- subset(data_long, variable == var & language == lang)
# Generate the plot for the current language and variable
p <- ggplot(data = data_filtered, aes(x = phase, y = value, fill = phase)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
scale_fill_manual(values = colorBlindBlack8) +
labs(x = "Syllable",
y = var,
title = lang) +
theme_minimal() +
theme(legend.position = "none")
# Dynamically generate the file name to include both language and variable
file_name <- paste0(plots, "/prepost_", var, "_", lang, ".pdf")
# Save the plot
ggsave(filename = file_name, plot = p, width = 10, height = 8)
}
}
# With lines
for (var in variables) {
for (lang in languages) {
# Filter data_long for the current language and variable
data_filtered <- subset(data_long, variable == var & language == lang)
# Generate the plot for the current language and variable
p <- ggplot(data = data_filtered, aes(x = phase, y = value, fill = phase)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
geom_line(aes(group = interaction(fileName, annotationNum)), color = "grey", alpha = 0.1) +
scale_fill_manual(values = colorBlindBlack8) +
labs(x = "Syllable",
y = var,
title = lang) +
theme_minimal() +
theme(legend.position = "none")
# Dynamically generate the file name to include both language and variable
file_name <- paste0(plots, "/prepost_", var, "_lines_", lang, ".pdf")
# Save the plot
ggsave(filename = file_name, plot = p, width = 10, height = 8)
}
}
# Clean up the environment
rm(languages, lang, variables, var, data_filtered)
# Define unique variables for plotting
variables <- unique(df_long$variable)
# Define unique variables for plotting
variables <- unique(df_long$variable)
# Define unique variables for plotting
variables <- unique(data_long$variable)
# Define unique variables for plotting
variables <- unique(data_long$variable)
# Without lines
for (var in variables) {
# Filter df_long for the current variable
data_filtered <- subset(data_long, variable == var)
# Generate the plot for the current variable
p <- ggplot(data = data_filtered, aes(x = phase, y = value, fill = language)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
scale_fill_manual(values = colorBlindBlack8) +
labs(x = "Syllable",
y = var) +
theme_minimal()
# Dynamically generate the file name to include the variable
file_name <- paste0(plots, "prepost_", var, ".pdf")
# Save the plot
ggsave(filename = file_name, plot = p, width = 10, height = 8)
}
# With lines
for (var in variables) {
# Filter df_long for the current variable
data_filtered <- subset(data_long, variable == var)
# Generate the plot for the current variable
p <- ggplot(data = data_filtered, aes(x = phase, y = value, fill = language)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
geom_line(aes(group = interaction(fileName, annotationNum)), color = "grey", alpha = 0.1) +
scale_fill_manual(values = colorBlindBlack8) +
labs(x = "Syllable",
y = var) +
theme_minimal()
# Dynamically generate the file name to include the variable
file_name <- paste0(plots, "prepost_", var, "_lines", ".pdf")
# Save the plot
ggsave(filename = file_name, plot = p, width = 10, height = 8)
}
# Clean up
rm(variables, var, data_filtered)
knitr::opts_chunk$set(echo = TRUE)
########## folders ##########
# current folder (first go to session -> set working directory -> to source file location)
parentfolder <- dirname(getwd())
data          <- paste0(parentfolder, '/MultIS_data/')
audiodata     <- paste0(parentfolder, '/audio_processed/')
syllables     <- paste0(audiodata,    'syllables/')
dataworkspace <- paste0(parentfolder, '/data_processed/')
datamerged    <- paste0(parentfolder, '/data_merged/')
datasets      <- paste0(parentfolder, '/datasets/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')
########## source file ##########
#source(paste0(scripts, "adjectives-preparation.R"))
#################### packages ####################
# Data Manipulation
library(tibble)
library(stringr)
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
# Plotting
library(ggforce)
library(ggpubr)
library(gridExtra)
# Random Forests and XGBoost
library(rpart)
library(rpart.plot)
library(ranger)
library(tuneRanger)
library(caret)
library(xgboost)
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
participant_info <- read_delim(paste0(data,"ParticipantInfo_GERCAT.csv"), delim = ";")
# Load the information about duration of each segment (if needed)
data_df <- read.table(paste0(syllables, "fileDurationsDF.csv"), header = TRUE, sep = ',')
# Load cleaned syllable data
data <- read_csv(paste0(datasets, "data_cleaned.csv"))
# Load cleaned targets data
targets <- read_csv(paste0(datasets, "targets.csv"))
# Load cleaned targets with pre-post data
data_prepost <- read_csv(paste0(datasets, "data_prepost.csv"))
str(data_prepost)
# Create data_prepost_german for rows where language is German
data_prepost_german <- data_prepost %>%
filter(language == "German")
# Create data_prepost_catalan for rows where language is Catalan
data_prepost_catalan <- data_prepost %>%
filter(language == "Catalan")
colnames(data_prepost_german)
# Create data_prepost_german for rows where language is German
data_prepost_ger <- data_prepost %>%
filter(language == "German")
# Create data_prepost_catalan for rows where language is Catalan
data_prepost_cat <- data_prepost %>%
filter(language == "Catalan")
gerTree <- rpart(
formula = percProm ~ money + last_pizza + exercise + self_loathing,  # Formula for the model
data = data_prepost_ger,  # Dataset containing the variables
method = "class",   # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
colnames(data_prepost_ger)
rm(data_prepost_catalan,data_prepost_german)
gerTree <- rpart(
formula = percProm ~ duration + duration_noSilence + ampl_median + ampl_noSilence_median + env_slope +
pitch_median_norm + pitch_sd_norm + f0_slope_norm + specCentroid_median + entropy_median +
HNR_median + amEnvDep_median + fmDep_median + durationPre + duration_noSilencePre +
ampl_medianPre + ampl_noSilence_medianPre + env_slopePre + pitch_median_normPre +
pitch_sd_normPre + f0_slope_normPre + specCentroid_medianPre + entropy_medianPre +
HNR_medianPre + amEnvDep_medianPre + fmDep_medianPre + durationPost + duration_noSilencePost +
ampl_medianPost + ampl_noSilence_medianPost + env_slopePost + pitch_median_normPost +
pitch_sd_normPost + f0_slope_normPost + specCentroid_medianPost + entropy_medianPost +
HNR_medianPost + amEnvDep_medianPost + fmDep_medianPost,  # Formula for the model
data = data_prepost_ger,  # Dataset containing the variables
method = "class",   # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
gerTree <- rpart(
formula = percProm ~ duration + ampl_median  + env_slope +
pitch_median_norm + pitch_sd_norm + f0_slope_norm + specCentroid_median + entropy_median +
HNR_median + amEnvDep_median + fmDep_median + durationPre +
ampl_medianPre + env_slopePre + pitch_median_normPre +
pitch_sd_normPre + f0_slope_normPre + specCentroid_medianPre + entropy_medianPre +
HNR_medianPre + amEnvDep_medianPre + fmDep_medianPre + durationPost +
ampl_medianPost + env_slopePost + pitch_median_normPost +
pitch_sd_normPost + f0_slope_normPost + specCentroid_medianPost + entropy_medianPost +
HNR_medianPost + amEnvDep_medianPost + fmDep_medianPost,  # Formula for the model
data = data_prepost_ger,  # Dataset containing the variables
method = "class",   # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 1     # Length of factor levels displayed on the plot (increase as needed)
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 1     # Length of factor levels displayed on the plot (increase as needed)
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
gerTree <- rpart(
formula = percProm ~ duration + ampl_median  + env_slope +
pitch_median_norm + pitch_sd_norm + f0_slope_norm + specCentroid_median + entropy_median +
HNR_median + amEnvDep_median + fmDep_median + durationPre +
ampl_medianPre + env_slopePre + pitch_median_normPre +
pitch_sd_normPre + f0_slope_normPre + specCentroid_medianPre + entropy_medianPre +
HNR_medianPre + amEnvDep_medianPre + fmDep_medianPre + durationPost +
ampl_medianPost + env_slopePost + pitch_median_normPost +
pitch_sd_normPost + f0_slope_normPost + specCentroid_medianPost + entropy_medianPost +
HNR_medianPost + amEnvDep_medianPost + fmDep_medianPost,  # Formula for the model
data = data_prepost_ger,  # Dataset containing the variables
method = "class",   # Specify that it's a classification tree
control = rpart.control(maxdepth = 7)  # Control parameters for the 'rpart' function
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
gerTree <- rpart(
formula = percProm ~ duration + ampl_median  + env_slope +
pitch_median_norm + pitch_sd_norm + f0_slope_norm + specCentroid_median + entropy_median +
HNR_median + amEnvDep_median + fmDep_median + durationPre +
ampl_medianPre + env_slopePre + pitch_median_normPre +
pitch_sd_normPre + f0_slope_normPre + specCentroid_medianPre + entropy_medianPre +
HNR_medianPre + amEnvDep_medianPre + fmDep_medianPre + durationPost +
ampl_medianPost + env_slopePost + pitch_median_normPost +
pitch_sd_normPost + f0_slope_normPost + specCentroid_medianPost + entropy_medianPost +
HNR_medianPost + amEnvDep_medianPost + fmDep_medianPost,  # Formula for the model
data = data_prepost_ger,  # Dataset containing the variables
method = "class",   # Specify that it's a classification tree
control = rpart.control(maxdepth = 7)  # Control parameters for the 'rpart' function
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
gerTree <- rpart(
formula = percProm ~ duration + ampl_median  + env_slope +
pitch_median_norm + pitch_sd_norm + f0_slope_norm + specCentroid_median + entropy_median +
HNR_median + amEnvDep_median + fmDep_median + durationPre +
ampl_medianPre + env_slopePre + pitch_median_normPre +
pitch_sd_normPre + f0_slope_normPre + specCentroid_medianPre + entropy_medianPre +
HNR_medianPre + amEnvDep_medianPre + fmDep_medianPre + durationPost +
ampl_medianPost + env_slopePost + pitch_median_normPost +
pitch_sd_normPost + f0_slope_normPost + specCentroid_medianPost + entropy_medianPost +
HNR_medianPost + amEnvDep_medianPost + fmDep_medianPost,  # Formula for the model
data = data_prepost_ger,  # Dataset containing the variables
method = "class",   # Specify that it's a classification tree
control = rpart.control(maxdepth = 5)  # Control parameters for the 'rpart' function
)
prp(
gerTree,         # The decision tree object to be visualized
extra = 1,      # Show extra information (like node statistics) in the plot
varlen = 0,     # Length of variable names (0 means auto-determined)
faclen = 0     # Length of factor levels displayed on the plot (increase as needed)
)
