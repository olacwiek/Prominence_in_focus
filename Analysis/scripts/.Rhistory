min(data_df$duration) # 19
mean(data_df$duration) # 216.651
max(data_df$duration) # 3528
data <- read_csv(paste0(datasets, "syllables_soundgen_summary.csv"))
# For which files, no data were extracted?
fileNames_not_in_data <- setdiff(data_df$fileName, data$file)
print(fileNames_not_in_data) # all pauses
# What is their duration?
# data_df[data_df$fileName %in% fileNames_not_in_data, ]
# Remove the duration column from data_df
data_df$duration <- data_df$duration / 1000
# Merge the two data frames by matching 'file' in data with 'fileName' in data_df
data <- merge(data_df, data, by.y = "file", by.x = "fileName", all = TRUE)
# Select and rename the duration.x column to duration, and filter itemType == "target"
data <- data %>%
filter(itemType == "target") %>%
select(-duration.y) %>%   # Remove duration.y if it exists
rename(duration = duration.x)
# Load in previously extracted data
df <- read.csv(paste0(datasets, "df.csv"))
# Select only the necessary columns from df for the merge
df <- df %>%
select(Language, Participant, Item_num, Focus, Word, Syll_num, F0_slope, env_slope) %>%
rename(f0_slope = F0_slope)
# Perform the left join to append F0_slope and env_slope to data
data <- data %>%
left_join(df, by = c("language" = "Language",
"participant" = "Participant",
"itemNum" = "Item_num",
"word" = "Word",
"focus" = "Focus",
"annotationNum" = "Syll_num"))
rm(df)
unique(data$syllText)
# Update df with modified 'syllText' values
data <- data %>%
mutate(syllText = case_when(
syllText == "-p-Y" ~ "-p-",
syllText == "Pre" ~ "pre",
syllText == "Post" ~ "post",
syllText == " ̞post "~ "post",
syllText == "	̞post "~ "post",
syllText == "post " ~ "post",
syllText == "posr" ~ "post",
syllText == "prepost" ~ "postpre",
syllText == "PrePost" ~ "postpre",
syllText == "PostPre" ~ "postpre",
syllText == "Postpre" ~ "postpre",
syllText == "post:pre" ~ "postpre",
syllText == "post-pre" ~ "postpre",
syllText == "post–pre" ~ "postpre",
syllText == "postPre" ~ "postpre",
syllText == "prepost" ~ "postpre",
syllText == "postpost" ~ "postpre",
syllText == "lopre "~ "lopre", # Remove trailing space
syllText == "postpre " ~ "postpre", # Remove trailing space
TRUE ~ syllText # Keep other values as they are
))
data <- data %>%
mutate(syllText = if_else(fileName == "G05_T_10_F_6_N_ ̞post_2", "post", syllText))
unique(data$syllText)
# Modify the data frame
data <- data %>%
mutate(percProm = ifelse(grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) | syllText == "", NA, percProm))
# Create a subset excluding non-target syllables
targets <- data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) & syllText != "")
# Filter rows with NA in percProm and select fileName
NA_percProm_targets <- targets %>%
filter(is.na(percProm)) %>%
select(fileName, percProm)
# # Write the resulting data frame to a CSV file
# write.csv(NA_percProm_targets, file = paste0(parentfolder,"/NA_percProm_targets.csv"), row.names = FALSE)
# Substitute missing percProm values
NA_percProm_targets$percProm <- c(2, 1, 2, 3, 2, 1, 2, 3, 2, 2, 2, 1, 1, 1, 0, 2, 3, 2, 2, 2, 1, 1, 2, 1, 2, 1, 3, 2, NA, 2, 1, 2, 2, 1, 2, 3, 3, 2, 2, 2)
data <- data %>%
left_join(NA_percProm_targets, by = "fileName") %>%
mutate(percProm = coalesce(percProm.y, percProm.x)) %>%
select(-percProm.x, -percProm.y)
# Correct column Word
data <- data %>%
# Replace "N\t" with "N"
mutate(word = gsub("N\\t", "N", word)) %>%
# Change "NP" to "N" and "Adj" to "A"
mutate(word = case_when(
word == "NP" ~ "N",
word == "Adj" ~ "A",
TRUE ~ word
)) %>%
# Convert Word column to factor after all replacements
mutate(word = as.factor(word)) %>%
# Conditionally filter out specific rows based on Syll_num and File, if Language column exists
{if("language" %in% colnames(.)) filter(., !(annotationNum == 8 & language == "Catalan" & participant == 8 & itemNum == 21) &
!(annotationNum == 2 & language == "German" & participant == 26 & itemNum == 31)) else .}
# Correct prominence ratings
data <- data %>%
# First, handle the specific updates for Prosodic_Prom
mutate(# Ensure Prosodic_Prom is numeric before applying case_when
percProm = as.numeric(percProm),
percProm = case_when(
"language" %in% colnames(data) & language == "German" & participant == 17 & itemNum == 35 & syllText == "pfan" ~ 2,
"language" %in% colnames(data) & language == "Catalan" & participant == 2 & itemNum == 13 & syllText == "lorpre" ~ 1,
"language" %in% colnames(data) & language == "Catalan" & participant == 2 & itemNum == 14 & syllText == "lorpre" ~ 1,
TRUE ~ percProm
)) %>%
# Conditionally filter out specific rows if Language column exists
{if("language" %in% colnames(.)) filter(., !(language == "German" & participant == 14 & itemNum == 22 & syllText == "an")) else .}
data <- data %>%
select(fileName, language, participant, itemType, itemNum, focus,
annotationNum, word, syllText, percProm,
duration, duration_noSilence,
ampl_median, ampl_sd,
ampl_noSilence_median, ampl_noSilence_sd, env_slope,
CPP_median, CPP_sd,
flux_median, flux_sd,
novelty_median, novelty_sd,
pitch_median, pitch_sd, f0_slope,
f1_freq_median, f2_freq_median,
specCentroid_median, specCentroid_sd,
entropy_median, entropy_sd,
entropySh_median, entropySh_sd,
HNR_median, HNR_sd,
amEnvDep_median, amEnvDep_sd,
fmDep_median, fmDep_sd)
# List of columns to normalize
columns_to_normalize <- c("pitch_median", "pitch_sd", "f0_slope", "f1_freq_median", "f2_freq_median")
# Calculate mean and standard deviation for each participant within each language
data_stats <- data %>%
group_by(language, participant) %>%
summarise(across(all_of(columns_to_normalize), list(mean = ~ mean(.x, na.rm = TRUE), sd = ~ sd(.x, na.rm = TRUE)), .names = "{.col}_{.fn}"))
# Normalize the values
data <- data %>%
left_join(data_stats, by = c("language", "participant")) %>%
mutate(across(all_of(columns_to_normalize),
list(norm = ~ (. - get(paste0(cur_column(), "_mean"))) / get(paste0(cur_column(), "_sd"))),
.names = "{.col}_norm")) %>%
select(-pitch_median_mean, -pitch_median_sd,
-pitch_sd_mean, -pitch_sd_sd,
-f0_slope_mean, -f0_slope_sd,
-f1_freq_median_mean, -f1_freq_median_sd,
-f2_freq_median_mean, -f2_freq_median_sd) # Optional: remove intermediate mean and sd columns
# Sort columns in the specified order
data <- data %>%
select(
fileName, language, participant, itemType, itemNum, focus, annotationNum,
word, syllText, percProm, duration, duration_noSilence, ampl_median,
ampl_noSilence_median, env_slope, pitch_median, pitch_median_norm, pitch_sd,
pitch_sd_norm, f0_slope, f0_slope_norm, f1_freq_median, f1_freq_median_norm,
f2_freq_median, f2_freq_median_norm, specCentroid_median, entropy_median,
HNR_median, amEnvDep_median, fmDep_median
)
rm(data_stats)
View(data)
data <- read_csv(paste0(datasets, "syllables_soundgen_summary.csv"))
# Remove the duration column from data_df
data_df$duration <- data_df$duration / 1000
# Merge the two data frames by matching 'file' in data with 'fileName' in data_df
data <- merge(data_df, data, by.y = "file", by.x = "fileName", all = TRUE)
# Select and rename the duration.x column to duration, and filter itemType == "target"
data <- data %>%
filter(itemType == "target") %>%
select(-duration.y) %>%   # Remove duration.y if it exists
rename(duration = duration.x)
# Load in previously extracted data
df <- read.csv(paste0(datasets, "df.csv"))
# Select only the necessary columns from df for the merge
df <- df %>%
select(Language, Participant, Item_num, Focus, Word, Syll_num, F0_slope, env_slope) %>%
rename(f0_slope = F0_slope)
# Perform the left join to append F0_slope and env_slope to data
data <- data %>%
left_join(df, by = c("language" = "Language",
"participant" = "Participant",
"itemNum" = "Item_num",
"word" = "Word",
"focus" = "Focus",
"annotationNum" = "Syll_num"))
rm(df)
unique(data$syllText)
# Update df with modified 'syllText' values
data <- data %>%
mutate(syllText = case_when(
syllText == "-p-Y" ~ "-p-",
syllText == "Pre" ~ "pre",
syllText == "Post" ~ "post",
syllText == " ̞post "~ "post",
syllText == "	̞post "~ "post",
syllText == "post " ~ "post",
syllText == "posr" ~ "post",
syllText == "prepost" ~ "postpre",
syllText == "PrePost" ~ "postpre",
syllText == "PostPre" ~ "postpre",
syllText == "Postpre" ~ "postpre",
syllText == "post:pre" ~ "postpre",
syllText == "post-pre" ~ "postpre",
syllText == "post–pre" ~ "postpre",
syllText == "postPre" ~ "postpre",
syllText == "prepost" ~ "postpre",
syllText == "postpost" ~ "postpre",
syllText == "lopre "~ "lopre", # Remove trailing space
syllText == "postpre " ~ "postpre", # Remove trailing space
TRUE ~ syllText # Keep other values as they are
))
data <- data %>%
mutate(syllText = if_else(fileName == "G05_T_10_F_6_N_ ̞post_2", "post", syllText))
unique(data$syllText)
# Modify the data frame
data <- data %>%
mutate(percProm = ifelse(grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) | syllText == "", NA, percProm))
# Create a subset excluding non-target syllables
targets <- data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) & syllText != "")
# Filter rows with NA in percProm and select fileName
NA_percProm_targets <- targets %>%
filter(is.na(percProm)) %>%
select(fileName, percProm)
# # Write the resulting data frame to a CSV file
# write.csv(NA_percProm_targets, file = paste0(parentfolder,"/NA_percProm_targets.csv"), row.names = FALSE)
# Substitute missing percProm values
NA_percProm_targets$percProm <- c(2, 1, 2, 3, 2, 1, 2, 3, 2, 2, 2, 1, 1, 1, 0, 2, 3, 2, 2, 2, 1, 1, 2, 1, 2, 1, 3, 2, NA, 2, 1, 2, 2, 1, 2, 3, 3, 2, 2, 2)
data <- data %>%
left_join(NA_percProm_targets, by = "fileName") %>%
mutate(percProm = coalesce(percProm.y, percProm.x)) %>%
select(-percProm.x, -percProm.y)
# Correct column Word
data <- data %>%
# Replace "N\t" with "N"
mutate(word = gsub("N\\t", "N", word)) %>%
# Change "NP" to "N" and "Adj" to "A"
mutate(word = case_when(
word == "NP" ~ "N",
word == "Adj" ~ "A",
TRUE ~ word
)) %>%
# Convert Word column to factor after all replacements
mutate(word = as.factor(word)) %>%
# Conditionally filter out specific rows based on Syll_num and File, if Language column exists
{if("language" %in% colnames(.)) filter(., !(annotationNum == 8 & language == "Catalan" & participant == 8 & itemNum == 21) &
!(annotationNum == 2 & language == "German" & participant == 26 & itemNum == 31)) else .}
# Correct prominence ratings
data <- data %>%
# First, handle the specific updates for Prosodic_Prom
mutate(# Ensure Prosodic_Prom is numeric before applying case_when
percProm = as.numeric(percProm),
percProm = case_when(
"language" %in% colnames(data) & language == "German" & participant == 17 & itemNum == 35 & syllText == "pfan" ~ 2,
"language" %in% colnames(data) & language == "Catalan" & participant == 2 & itemNum == 13 & syllText == "lorpre" ~ 1,
"language" %in% colnames(data) & language == "Catalan" & participant == 2 & itemNum == 14 & syllText == "lorpre" ~ 1,
TRUE ~ percProm
)) %>%
# Conditionally filter out specific rows if Language column exists
{if("language" %in% colnames(.)) filter(., !(language == "German" & participant == 14 & itemNum == 22 & syllText == "an")) else .}
data <- data %>%
select(fileName, language, participant, itemType, itemNum, focus,
annotationNum, word, syllText, percProm,
duration, duration_noSilence,
ampl_median, ampl_sd,
ampl_noSilence_median, ampl_noSilence_sd, env_slope,
CPP_median, CPP_sd,
flux_median, flux_sd,
novelty_median, novelty_sd,
pitch_median, pitch_sd, f0_slope,
f1_freq_median, f2_freq_median,
specCentroid_median, specCentroid_sd,
entropy_median, entropy_sd,
entropySh_median, entropySh_sd,
HNR_median, HNR_sd,
amEnvDep_median, amEnvDep_sd,
fmDep_median, fmDep_sd)
# List of columns to normalize
columns_to_normalize <- c("pitch_median", "pitch_sd", "f0_slope", "f1_freq_median", "f2_freq_median")
# Calculate mean and standard deviation for each participant within each language
data_stats <- data %>%
group_by(language, participant) %>%
summarise(across(all_of(columns_to_normalize), list(mean = ~ mean(.x, na.rm = TRUE), sd = ~ sd(.x, na.rm = TRUE)), .names = "{.col}_{.fn}"))
# Normalize the values
data <- data %>%
left_join(data_stats, by = c("language", "participant")) %>%
mutate(across(all_of(columns_to_normalize),
list(norm = ~ (. - get(paste0(cur_column(), "_mean"))) / get(paste0(cur_column(), "_sd"))),
.names = "{.col}_norm")) %>%
select(-pitch_median_mean, -pitch_median_sd,
-pitch_sd_mean, -pitch_sd_sd,
-f0_slope_mean, -f0_slope_sd,
-f1_freq_median_mean, -f1_freq_median_sd,
-f2_freq_median_mean, -f2_freq_median_sd) # Optional: remove intermediate mean and sd columns
# Sort columns in the specified order
data <- data %>%
select(
fileName, language, participant, itemType, itemNum, focus, annotationNum,
word, syllText, percProm, duration, duration_noSilence, ampl_median,
ampl_noSilence_median, env_slope, pitch_median, pitch_median_norm, pitch_sd,
pitch_sd_norm, f0_slope, f0_slope_norm, f1_freq_median, f1_freq_median_norm,
f2_freq_median, f2_freq_median_norm, specCentroid_median, entropy_median,
HNR_median, amEnvDep_median, fmDep_median
)
rm(data_stats)
data <- read_csv(paste0(datasets, "syllables_soundgen_summary.csv"))
# For which files, no data were extracted?
fileNames_not_in_data <- setdiff(data_df$fileName, data$file)
print(fileNames_not_in_data) # all pauses
# What is their duration?
# data_df[data_df$fileName %in% fileNames_not_in_data, ]
# Remove the duration column from data_df
data_df$duration <- data_df$duration / 1000
# Merge the two data frames by matching 'file' in data with 'fileName' in data_df
data <- merge(data_df, data, by.y = "file", by.x = "fileName", all = TRUE)
# Select and rename the duration.x column to duration, and filter itemType == "target"
data <- data %>%
filter(itemType == "target") %>%
select(-duration.y) %>%   # Remove duration.y if it exists
rename(duration = duration.x)
# Load in previously extracted data
df <- read.csv(paste0(datasets, "df.csv"))
# Select only the necessary columns from df for the merge
df <- df %>%
select(Language, Participant, Item_num, Focus, Word, Syll_num, F0_slope, env_slope) %>%
rename(f0_slope = F0_slope)
# Perform the left join to append F0_slope and env_slope to data
data <- data %>%
left_join(df, by = c("language" = "Language",
"participant" = "Participant",
"itemNum" = "Item_num",
"word" = "Word",
"focus" = "Focus",
"annotationNum" = "Syll_num"))
rm(df)
unique(data$syllText)
# Update df with modified 'syllText' values
data <- data %>%
mutate(syllText = case_when(
syllText == "-p-Y" ~ "-p-",
syllText == "Pre" ~ "pre",
syllText == "Post" ~ "post",
syllText == " ̞post "~ "post",
syllText == "	̞post "~ "post",
syllText == "post " ~ "post",
syllText == "posr" ~ "post",
syllText == "prepost" ~ "postpre",
syllText == "PrePost" ~ "postpre",
syllText == "PostPre" ~ "postpre",
syllText == "Postpre" ~ "postpre",
syllText == "post:pre" ~ "postpre",
syllText == "post-pre" ~ "postpre",
syllText == "post–pre" ~ "postpre",
syllText == "postPre" ~ "postpre",
syllText == "prepost" ~ "postpre",
syllText == "postpost" ~ "postpre",
syllText == "lopre "~ "lopre", # Remove trailing space
syllText == "postpre " ~ "postpre", # Remove trailing space
TRUE ~ syllText # Keep other values as they are
))
data <- data %>%
mutate(syllText = if_else(fileName == "G05_T_10_F_6_N_ ̞post_2", "post", syllText))
unique(data$syllText)
# Modify the data frame
data <- data %>%
mutate(percProm = ifelse(grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) | syllText == "", NA, percProm))
# Create a subset excluding non-target syllables
targets <- data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) & syllText != "")
# Filter rows with NA in percProm and select fileName
NA_percProm_targets <- targets %>%
filter(is.na(percProm)) %>%
select(fileName, percProm)
# # Write the resulting data frame to a CSV file
# write.csv(NA_percProm_targets, file = paste0(parentfolder,"/NA_percProm_targets.csv"), row.names = FALSE)
# Substitute missing percProm values
NA_percProm_targets$percProm <- c(2, 1, 2, 3, 2, 1, 2, 3, 2, 2, 2, 1, 1, 1, 0, 2, 3, 2, 2, 2, 1, 1, 2, 1, 2, 1, 3, 2, NA, 2, 1, 2, 2, 1, 2, 3, 3, 2, 2, 2)
data <- data %>%
left_join(NA_percProm_targets, by = "fileName") %>%
mutate(percProm = coalesce(percProm.y, percProm.x)) %>%
select(-percProm.x, -percProm.y)
# Correct column Word
data <- data %>%
# Replace "N\t" with "N"
mutate(word = gsub("N\\t", "N", word)) %>%
# Change "NP" to "N" and "Adj" to "A"
mutate(word = case_when(
word == "NP" ~ "N",
word == "Adj" ~ "A",
TRUE ~ word
)) %>%
# Convert Word column to factor after all replacements
mutate(word = as.factor(word)) %>%
# Conditionally filter out specific rows based on Syll_num and File, if Language column exists
{if("language" %in% colnames(.)) filter(., !(annotationNum == 8 & language == "Catalan" & participant == 8 & itemNum == 21) &
!(annotationNum == 2 & language == "German" & participant == 26 & itemNum == 31)) else .}
# Correct prominence ratings
data <- data %>%
# First, handle the specific updates for Prosodic_Prom
mutate(# Ensure Prosodic_Prom is numeric before applying case_when
percProm = as.numeric(percProm),
percProm = case_when(
"language" %in% colnames(data) & language == "German" & participant == 17 & itemNum == 35 & syllText == "pfan" ~ 2,
"language" %in% colnames(data) & language == "Catalan" & participant == 2 & itemNum == 13 & syllText == "lorpre" ~ 1,
"language" %in% colnames(data) & language == "Catalan" & participant == 2 & itemNum == 14 & syllText == "lorpre" ~ 1,
TRUE ~ percProm
)) %>%
# Conditionally filter out specific rows if Language column exists
{if("language" %in% colnames(.)) filter(., !(language == "German" & participant == 14 & itemNum == 22 & syllText == "an")) else .}
data <- data %>%
select(fileName, language, participant, itemType, itemNum, focus,
annotationNum, word, syllText, percProm,
duration, duration_noSilence,
ampl_median, ampl_sd,
ampl_noSilence_median, ampl_noSilence_sd, env_slope,
CPP_median, CPP_sd,
flux_median, flux_sd,
novelty_median, novelty_sd,
pitch_median, pitch_sd, f0_slope,
f1_freq_median, f2_freq_median,
specCentroid_median, specCentroid_sd,
entropy_median, entropy_sd,
entropySh_median, entropySh_sd,
HNR_median, HNR_sd,
amEnvDep_median, amEnvDep_sd,
fmDep_median, fmDep_sd)
# List of columns to normalize
columns_to_normalize <- c("pitch_median", "pitch_sd", "f0_slope", "f1_freq_median", "f2_freq_median")
# Calculate mean and standard deviation for each participant within each language
data_stats <- data %>%
group_by(language, participant) %>%
summarise(across(all_of(columns_to_normalize), list(mean = ~ mean(.x, na.rm = TRUE), sd = ~ sd(.x, na.rm = TRUE)), .names = "{.col}_{.fn}"))
# Normalize the values
data <- data %>%
left_join(data_stats, by = c("language", "participant")) %>%
mutate(across(all_of(columns_to_normalize),
list(norm = ~ (. - get(paste0(cur_column(), "_mean"))) / get(paste0(cur_column(), "_sd"))),
.names = "{.col}_norm")) %>%
select(-pitch_median_mean, -pitch_median_sd,
-pitch_sd_mean, -pitch_sd_sd,
-f0_slope_mean, -f0_slope_sd,
-f1_freq_median_mean, -f1_freq_median_sd,
-f2_freq_median_mean, -f2_freq_median_sd) # Optional: remove intermediate mean and sd columns
# Sort columns in the specified order
data <- data %>%
select(
fileName, language, participant, itemType, itemNum, focus,
annotationNum, word, syllText, percProm,
duration, duration_noSilence,
ampl_median, ampl_sd,
ampl_noSilence_median, ampl_noSilence_sd, env_slope,
CPP_median, CPP_sd,
flux_median, flux_sd,
novelty_median, novelty_sd,
pitch_median, pitch_sd, pitch_sd_norm, f0_slope, f0_slope_norm,
f1_freq_median, f1_freq_median_norm,
f2_freq_median, f2_freq_median_norm,
specCentroid_median, specCentroid_sd,
entropy_median, entropy_sd,
entropySh_median, entropySh_sd,
HNR_median, HNR_sd,
amEnvDep_median, amEnvDep_sd,
fmDep_median, fmDep_sd
)
rm(data_stats)
# Update targets
targets <- data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE) & syllText != "")
write.csv(targets, file = paste0(datasets, "targets.csv"), row.names = FALSE)
# Combined process to find "pre" and "post" syllables
data_prepost <- data %>%
# First, find rows that do not match the initial exclusion criteria
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE)) %>%
## PRE - Step 1
# Create a new data frame for finding the corresponding "pre" syllables for annotationNum - 1
mutate(annotationNumTarget = annotationNum - 1) %>%
# Join data with itself based on relevant columns
left_join(data, by = c("language", "participant", "itemType", "itemNum", "focus", "annotationNumTarget" = "annotationNum"), suffix = c("", ".pre1")) %>%
# Modify the joined columns to be NA where syllText.pre1 does not contain "pre"
mutate(across(ends_with(".pre1"), ~ if_else(grepl("pre", syllText.pre1), ., NA), .names = "{.col}")) %>%
## PRE - Step 2
# Create a new data frame for finding the corresponding "pre" syllables for annotationNum - 2
mutate(annotationNumTarget = annotationNum - 2) %>%
# Join data with itself based on relevant columns
left_join(data, by = c("language", "participant", "itemType", "itemNum", "focus", "annotationNumTarget" = "annotationNum"), suffix = c("", ".pre2")) %>%
# Modify the joined columns to be NA where syllText.pre2 does not contain "pre"
mutate(across(ends_with(".pre2"), ~ if_else(grepl("pre", syllText.pre2), ., NA), .names = "{.col}")) %>%
# Combine the results of both pre steps, keeping only one set of pre columns
mutate(
across(ends_with(".pre2"), ~ if_else(!is.na(.), ., get(sub(".pre2$", ".pre1", cur_column()))), .names = "{.col}")
) %>%
select(-ends_with(".pre1")) %>%
rename_with(~ sub("\\.pre2$", "Pre", .), ends_with(".pre2")) %>%
## POST
# Create a new data frame for finding the corresponding "post" syllables
mutate(annotationNumTarget = annotationNum + 1) %>%
# Join data with itself based on relevant columns
left_join(data, by = c("language", "participant", "itemType", "itemNum", "focus", "annotationNumTarget" = "annotationNum"), suffix = c("", ".post")) %>%
# Modify the joined columns to be NA where syllText.post does not contain "post"
mutate(across(ends_with(".post"), ~ if_else(grepl("post", syllText.post), ., NA), .names = "{.col}")) %>%
## Ensure all target syllables are included
right_join(data %>%
filter(!grepl("pre|post|postpre|disfluency|break|-p-", syllText, ignore.case = TRUE)),
by = c("fileName", "annotationNum", "language", "participant", "itemType", "itemNum", "focus")) %>%
# Dynamically rename columns that end with .post to end with Post
rename_with(~ sub("\\.post$", "Post", .), ends_with(".post")) %>%
# Remove redundant columns
select(-ends_with(".y")) %>%
# Final renaming to remove .x and ensure column uniqueness
rename_with(~ sub("\\.x$", "", .), ends_with(".x")) %>%
# Remove unnecessary columns
select(-fileNamePre, -wordPre, -fileNamePost, -wordPost, -percPromPost, -percPromPre) %>%
# Sort columns so that "percProm" comes after "syllText"
select(fileName, language, participant, itemType, itemNum, focus, annotationNum, word, syllText, percProm,
everything())
# Find the missing fileNames in data_prepost compared to targets
#missing_from_prepost <- anti_join(data_prepost, targets, by = "fileName")
write.csv(data, file = paste0(datasets, "data_cleaned.csv"), row.names = FALSE)
write.csv(data_prepost, file = paste0(datasets, "data_prepost.csv"), row.names = FALSE)
R.version
