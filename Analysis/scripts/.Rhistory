# Here I hack brms' kfold code to make it run in parallel using good old mclapply instead of futures
# this avoid random crashes which seem to be due to future, but works only on *NIX (which, for me here, is not an issue)
# Adapted the code from https://github.com/paul-buerkner/brms/blob/master/R/loo.R and https://github.com/paul-buerkner/brms/blob/master/R/kfold.R
if( Sys.info()['sysname'] == "Windows" )
{
# In Windows, fall back to the stadard implementation in brms:
add_criterion_kfold_parallel <- function(model, K=10, chains=1)
{
return (add_criterion(model, criterion="kfold", K=K, chains=chains));
}
} else
{
# On anything else, try to use maclapply:
add_criterion_kfold_parallel <- function(model, K=10, chains=1)
{
model <- restructure(model);
mf <- model.frame(model);
attributes(mf)[c("terms", "brmsframe")] <- NULL;
N <- nrow(mf);
if( K > N ) return (model); # does not work in this case...
fold_type <- "random"; folds <- loo::kfold_split_random(K, N);
Ksub <- seq_len(K);
kfold_results <- mclapply(Ksub, function(k)
{
omitted <- predicted <- which(folds == k);
mf_omitted <- mf[-omitted, , drop=FALSE];
if( exists("subset_data2", envir=asNamespace("brms")) )
{
# Newer versions of brms:
model_updated <- base::suppressWarnings(update(model, newdata=mf_omitted, data2=brms:::subset_data2(model$data2, -omitted), refresh=0, chains=chains));
lppds <- log_lik(model_updated, newdata=mf[predicted, , drop=FALSE], newdata2=brms:::subset_data2(model$data2, predicted),
allow_new_levels=TRUE, resp=NULL, combine=TRUE, chains=chains);
} else if( exists("subset_autocor", envir=asNamespace("brms")) )
{
# Older versions of brms:
model2 <- brms:::subset_autocor(model, -omitted, incl_car=TRUE);
model_updated <- base::suppressWarnings(update(model2, newdata=mf_omitted, refresh=0, chains=chains));
lppds <- log_lik(model_updated, newdata=mf[predicted, , drop=FALSE], allow_new_levels=TRUE, resp=NULL, combine=TRUE, chains=chains);
} else
{
stop("Unknown version of brms!");
}
return (list("obs_order"=predicted, "lppds"=lppds));
}, mc.cores=ifelse(exists("brms_ncores"), brms_ncores, detectCores()));
# Put them back in the form expected by the the following unmodifed code:
obs_order <- lapply(kfold_results, function(x) x$obs_order);
lppds     <- lapply(kfold_results, function(x) x$lppds);
elpds <- brms:::ulapply(lppds, function(x) apply(x, 2, brms:::log_mean_exp))
# make sure elpds are put back in the right order
elpds <- elpds[order(unlist(obs_order))]
elpd_kfold <- sum(elpds)
se_elpd_kfold <- sqrt(length(elpds) * var(elpds))
rnames <- c("elpd_kfold", "p_kfold", "kfoldic")
cnames <- c("Estimate", "SE")
estimates <- matrix(nrow = 3, ncol = 2, dimnames = list(rnames, cnames))
estimates[1, ] <- c(elpd_kfold, se_elpd_kfold)
estimates[3, ] <- c(-2 * elpd_kfold, 2 * se_elpd_kfold)
out <- brms:::nlist(estimates, pointwise = cbind(elpd_kfold = elpds))
atts <- brms:::nlist(K, Ksub, NULL, folds, fold_type)
attributes(out)[names(atts)] <- atts
out <- structure(out, class = c("kfold", "loo"))
attr(out, "yhash") <- brms:::hash_response(model, newdata=NULL, resp=NULL);
attr(out, "model_name") <- "";
model$criteria$kfold <- out;
model;
}
}
# Bayesian fit indices for a given model:
brms_fit_indices <- function(model, indices=c("bayes_R2", "loo", "waic", "kfold"), K=10, verbose=TRUE, do.parallel=TRUE)
{
if( "bayes_R2" %in% indices )
{
if( verbose) cat("R^2...\n");
#attr(model, "R2") <- bayes_R2(model);
model <- add_criterion(model, "bayes_R2");
} else
{
# Remove the criterion (if already there):
if( !is.null(model$criteria) && "bayes_R2" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "bayes_R2") ]] <- NULL;
}
if( "loo" %in% indices )
{
if( verbose) cat("LOO...\n");
model <- add_criterion(model, "loo");
} else
{
# Remove the criterion (if already there):
if( !is.null(model$criteria) && "loo" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "loo") ]] <- NULL;
}
if( "waic" %in% indices )
{
if( verbose) cat("WAIC...\n");
model <- add_criterion(model, "waic");
} else
{
# Remove the criterion (if already there):
if( !is.null(model$criteria) && "waic" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "waic") ]] <- NULL;
}
if( "kfold" %in% indices )
{
if( verbose) cat(paste0("KFOLD (K=",K,")...\n"));
model1 <- NULL;
if( !do.parallel )
{
try(model1 <- add_criterion(model, "kfold", K=K, chains=1), silent=TRUE);
} else
{
try(model1 <- add_criterion_kfold_parallel(model, K=K, chains=1), silent=TRUE);
}
if( !is.null(model1) )
{
model <- model1;
} else
{
# Remove the criterion (if already there):
if( !is.null(model$criteria) && "kfold" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "kfold") ]] <- NULL;
}
} else
{
# Remove the criterion (if already there):
if( !is.null(model$criteria) && "kfold" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "kfold") ]] <- NULL;
}
gc();
return (model);
}
# Bayesian model comparison:
#model1 <- b_uvbm__blue
#model2 <- b_popsize__blue
brms_compare_models <- function(model1, model2, name1=NA, name2=NA, bayes_factor=TRUE, print_results=TRUE)
{
if( !is.null(model1$criteria) && "bayes_R2" %in% names(model1$criteria) && !is.null(model1$criteria$bayes_R2) &&
!is.null(model2$criteria) && "bayes_R2" %in% names(model2$criteria) && !is.null(model2$criteria$bayes_R2) )
{
R2_1_2 <- (mean(model1$criteria$bayes_R2) - mean(model2$criteria$bayes_R2));
} else
{
R2_1_2 <- NA;
}
if( bayes_factor )
{
invisible(capture.output(bf_1_2 <- brms::bayes_factor(model1, model2)$bf));
bf_interpret_1_2 <- BF_interpretation(bf_1_2, ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2"));
}
else
{
bf_1_2 <- NULL; bf_interpret_1_2 <- NA;
}
if( !is.null(model1$criteria) && "loo" %in% names(model1$criteria) && !is.null(model1$criteria$loo) &&
!is.null(model2$criteria) && "loo" %in% names(model2$criteria) && !is.null(model2$criteria$loo) )
{
loo_1_2 <- loo_compare(model1, model2, criterion="loo", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
} else
{
loo_1_2 <- NA;
}
if( !is.null(model1$criteria) && "waic" %in% names(model1$criteria) && !is.null(model1$criteria$waic) &&
!is.null(model2$criteria) && "waic" %in% names(model2$criteria) && !is.null(model2$criteria$waic) )
{
waic_1_2 <- loo_compare(model1, model2, criterion="waic", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
mw_1_2 <- model_weights(model1, model2, weights="waic", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
} else
{
waic_1_2 <- NA;
mw_1_2 <- NA;
}
if( !is.null(model1$criteria) && "kfold" %in% names(model1$criteria) && !is.null(model1$criteria$kfold) &&
!is.null(model2$criteria) && "kfold" %in% names(model2$criteria) && !is.null(model2$criteria$kfold) )
{
kfold_1_2 <- loo_compare(model1, model2, criterion="kfold", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
} else
{
kfold_1_2 <- NA;
}
if( print_results )
{
cat(paste0("\nComparing models '",ifelse(!is.na(name1), name1, "model1"),"' and '",ifelse(!is.na(name2), name2, "model2"),"':\n\n"));
cat(paste0("\ndelta R^2 = ",sprintf("%.1f%%",100*R2_1_2),"\n\n"));
cat(bf_interpret_1_2,"\n\n");
cat("\nLOO:\n"); print(loo_1_2);
cat("\nWAIC:\n"); print(waic_1_2);
cat("\nKFOLD:\n"); print(kfold_1_2);
cat("\nModel weights (WAIC):\n"); print(mw_1_2);
cat("\n");
}
gc();
return (list("R2"=R2_1_2, "BF"=bf_1_2, "BF_interpretation"=bf_interpret_1_2, "LOO"=loo_1_2, "WAIC"=waic_1_2, "KFOLD"=kfold_1_2, "model_weights_WAIC"=mw_1_2));
}
# print model comparisons
.print.model.comparison <- function(a=NULL, a.names=NULL, b=NULL) # a is the anova and b is the Bayesian comparison (only one can be non-NULL), a.names are the mappings between the inner and user-friendly model names
{
# ANOVA:
if( !is.null(a) )
{
a <- as.data.frame(a);
if( !is.null(a.names) )
{
if( length(a.names) != nrow(a) || !all(names(a.names) %in% rownames(a)) )
{
stop("a.names do not correspond the anova model names!");
return (NULL);
}
rownames(a) <- a.names[rownames(a)];
}
i <- which.min(a$AIC);
s.a <- sprintf("%s %s %s: ΔAIC=%.1f, ΔBIC=%.1f",
rownames(a)[i],
ifelse((!is.na(a[2,"Pr(>Chisq)"]) && a[2,"Pr(>Chisq)"] <0.05) || (abs(a$AIC[1] - a$AIC[2]) > 3), ">", "≈"),
rownames(a)[3-i],
abs(a$AIC[1] - a$AIC[2]),
abs(a$BIC[1] - a$BIC[2]));
if( !is.na(a[2,"Pr(>Chisq)"]) )
{
s.a <- paste0(s.a,
sprintf(", *p*=%s", scinot(a[2,"Pr(>Chisq)"])));
}
# return value:
return (s.a);
}
# Bayesian comparison:
if( !is.null(b) )
{
s.b <- sprintf("BF: %s, ΔLOO(%s %s %s)=%.1f (%.1f), ΔWAIC(%s %s %s)=%.1f (%.1f), ΔKFOLD(%s %s %s)=%.1f (%.1f)",
# BF:
b$BF_interpretation,
# LOO:
rownames(b$LOO)[1],
ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 4 || abs(b$LOO[1,1]-b$LOO[2,1]) < b$LOO[2,2], "≈", ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 2*b$LOO[2,2], ">", ">>")),
rownames(b$LOO)[2],
abs(b$LOO[1,1]-b$LOO[2,1]), b$LOO[2,2],
# WAIC:
rownames(b$WAIC)[1],
ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 4 || abs(b$WAIC[1,1]-b$WAIC[2,1]) < b$WAIC[2,2], "≈", ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 2*b$WAIC[2,2], ">", ">>")),
rownames(b$WAIC)[2],
abs(b$WAIC[1,1]-b$WAIC[2,1]), b$WAIC[2,2],
# KFOLD:
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", rownames(b$KFOLD)[1]),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 4 || abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < b$KFOLD[2,2], "≈", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 2*b$KFOLD[2,2], ">", ">>"))),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", rownames(b$KFOLD)[2]),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), NA, abs(b$KFOLD[1,1]-b$KFOLD[2,1])), ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), NA, b$KFOLD[2,2]));
# return value:
return (s.b);
}
}
# Standard error of the mean:
std <- function(x) sd(x)/sqrt(length(x))
# Root Mean Square Error (RMSE) between observed (y) and predicted (yrep) values:
rmse <- function(y, yrep)
{
yrep_mean <- colMeans(yrep)
sqrt(mean((yrep_mean - y)^2))
}
# Log odds to probability (logistic regression):
lo2p <- function(x){ o <- exp(x); return (o/(1+o));}
# Scientific notation using Markdown conventions (inspired from https://www.r-bloggers.com/2015/03/scientific-notation-for-rlatex/):
scinot <- function(xs, digits=2, pvalue=TRUE)
{
scinot1 <- function(x)
{
sign <- "";
if(x < 0)
{
sign <- "-";
x <- -x;
}
exponent <- floor(log10(x));
if(exponent && pvalue && exponent < -3)
{
xx <- round(x / 10^exponent, digits=digits);
e <- paste0("×10^", round(exponent,0), "^");
} else
{
xx <- round(x, digits=digits+1);
e <- "";
}
paste0(sign, xx, e);
}
vapply(xs, scinot1, character(1));
}
# Escape * in a string:
escstar <- function(s)
{
gsub("*", "\\*", s, fixed=TRUE);
}
# Chunk 4
packageVersion('tidyverse')
packageVersion('ggplot2')
packageVersion('brms')
#packageVersion('cmdstanr')
packageVersion('ggdist')
# Chunk 5
source('theme_timo.R')
df <- read.csv(paste0(data, "df.csv"))
########## folders ##########
# current folder (first go to session -> set working directory -> to source file location)
parentfolder <- dirname(getwd())
data          <- paste0(parentfolder, '/MultIS_data/')
audiodata     <- paste0(parentfolder, '/audio_processed/')
dataworkspace <- paste0(parentfolder, '/data_processed/')
datamerged    <- paste0(parentfolder, '/data_merged/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')
########## source file ##########
#source(paste0(scripts, "adjectives-preparation.R"))
#################### packages ####################
# audiovisual processing
library(seewave) # this for signal processing
library(signal)
library(rPraat)
library(dplR)
library(signal)
library(rstudioapi)
library(stringr)
library(wrassp)
library(readr)
library(readxl)
library(readtextgrid)   #reading txt grids
library(textgRid)
library(zoo)
library(pracma)
#library(stringi) # for syllable replacement
library(tuneR)
# data manipulation and viz
library(tidyverse)
library(ggpubr)
library(gridExtra)
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# modeling
library(broom) # for tidy model outputs
library(brms)
library(cmdstanr)
library(HDInterval) # package for credible interval computation
library(tidybayes) # plotting
library(bayesplot)
# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
# Bayes factor
#library(BayesFactor)
library(bayestestR)
# Diagnostics GUI
library(shinystan)
df <- read.csv(paste0(data, "df.csv"))
setwd("~/GitHub/Prominence_in_focus/Analysis/scripts")
########## folders ##########
# current folder (first go to session -> set working directory -> to source file location)
parentfolder <- dirname(getwd())
data          <- paste0(parentfolder, '/MultIS_data/')
audiodata     <- paste0(parentfolder, '/audio_processed/')
dataworkspace <- paste0(parentfolder, '/data_processed/')
datamerged    <- paste0(parentfolder, '/data_merged/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')
########## source file ##########
#source(paste0(scripts, "adjectives-preparation.R"))
#################### packages ####################
# audiovisual processing
library(seewave) # this for signal processing
library(signal)
library(rPraat)
library(dplR)
library(signal)
library(rstudioapi)
library(stringr)
library(wrassp)
library(readr)
library(readxl)
library(readtextgrid)   #reading txt grids
library(textgRid)
library(zoo)
library(pracma)
#library(stringi) # for syllable replacement
library(tuneR)
# data manipulation and viz
library(tidyverse)
library(ggpubr)
library(gridExtra)
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# modeling
library(broom) # for tidy model outputs
library(brms)
library(cmdstanr)
library(HDInterval) # package for credible interval computation
library(tidybayes) # plotting
library(bayesplot)
# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
# Bayes factor
#library(BayesFactor)
library(bayestestR)
# Diagnostics GUI
library(shinystan)
df <- read.csv(paste0(data, "df.csv"))
# Update df with modified 'Syll' values
df <- df %>%
mutate(Syll = case_when(
Syll == "<p>Y" ~ "<p>",
Syll == "Pre" ~ "pre",
Syll == "Post" ~ "post",
Syll == "pre_post" ~ "post_pre",
Syll == "Pre_Post" ~ "post_pre",
Syll == "Post_Pre" ~ "post_pre",
Syll == "Post_pre" ~ "post_pre",
Syll == "post:pre" ~ "post_pre",
Syll == "post-pre" ~ "post_pre",
Syll == "post–pre" ~ "post_pre",
Syll == "post_Pre" ~ "post_pre",
Syll == "prepost" ~ "post_pre",
Syll == "post_post" ~ "post_pre",
Syll == "post_pre " ~ "post_pre", # Remove trailing space
TRUE ~ Syll # Keep other values as they are
))
unique(df$Syll)
df <- df %>%
# Replace "N\t" with "N"
mutate(Word = gsub("N\\t", "N", Word)) %>%
# Change "NP" to "N" and "Adj" to "A"
mutate(Word = case_when(
Word == "NP" ~ "N",
Word == "Adj" ~ "A",
TRUE ~ Word
)) %>%
# Convert Word column to factor after all replacements
mutate(Word = as.factor(Word)) %>%
# Filter out specific rows based on Syll_num and File
filter(!(Syll_num == 8 & File == "C08_T_21_C") &
!(Syll_num == 2 & File == "G26_T_31_B"))
df <- df %>%
# First, handle the specific updates for Prosodic_Prom
mutate(# Ensure Prosodic_Prom is numeric before applying case_when
Prosodic_Prom = as.numeric(Prosodic_Prom),
Prosodic_Prom = case_when(
File == "G17_T_35_B" & Syll == "pfan" ~ 2,
File == "C02_T_13_I" & Syll == "lor_pre" ~ 1,
File == "C02_T_14_F" & Syll == "lor_pre" ~ 1,
TRUE ~ Prosodic_Prom
)) %>%
# Then, filter out the specific row to delete
# This case is arguably important, but since it is not the real target word, I delete it
filter(!(File == "G14_T_22_R" & Syll == "an"))
# Create subset without pre and post-tonic
df_targets <- df %>%
filter(!(Syll %in% c("pre", "post", "", "post_pre", "disfluency", "break", "<p>")))
# Columns to process
columns_to_process <- c("duration", "F0_mean", "F0_max", "F0_min", "F0_range",
"env_mean", "env_max", "env_min", "env_range"
)
# Function to calculate raw number and proportion of NAs
calculate_na_stats <- function(df, columns) {
na_counts <- colSums(is.na(df[, columns]))
total_counts <- nrow(df)
proportions <- na_counts / total_counts * 100
return(data.frame("NA_Count" = na_counts, "Proportion" = proportions))
}
# Initial NA stats
na_stats_before <- calculate_na_stats(df_targets, columns_to_process)
print(na_stats_before)
View(df_targets)
# Loop through each column and replace Inf and -Inf with NA
for (col_name in columns_to_process) {
# Replace Inf and -Inf with NA
df[[col_name]][df[[col_name]] == Inf | df[[col_name]] == -Inf] <- NA
}
# Process targets again
df_targets <- df %>%
filter(!(Syll %in% c("pre", "post", "", "post_pre", "disfluency", "break", "<p>")))
# NA stats after replacing Inf and -Inf
na_stats_after_replacement <- calculate_na_stats(df_targets, columns_to_process)
print(na_stats_after_replacement)
# Initialize a list to store outlier information
outliers_info <- list()
# Loop through each column
for (col_name in columns_to_process) {
cat("Processing column:", col_name, "\n")
# Calculate IQR
Q1 <- quantile(df[[col_name]], 0.25, na.rm = TRUE)
Q3 <- quantile(df[[col_name]], 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Define lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Identify outliers
outliers <- df[[col_name]] < lower_bound | df[[col_name]] > upper_bound
# Get outlier information
outliers_info[[col_name]] <- list(
N_outliers = sum(outliers, na.rm = TRUE),
Prop_outliers = (sum(outliers, na.rm = TRUE) / length(df[[col_name]])) * 100,
Mean_outliers = mean(df[[col_name]][outliers], na.rm = TRUE),
Mean_with_outliers = mean(df[[col_name]], na.rm = TRUE),
Mean_without_outliers = mean(df[[col_name]][!outliers], na.rm = TRUE)
)
# Replace outliers with NA
df[[col_name]][outliers] <- NA
}
# Create a summary table
outliers_summary <- data.frame(t(sapply(outliers_info, unlist)))
colnames(outliers_summary) <- c("N_outliers", "Prop_outliers", "Mean_outliers", "Mean_with_outliers", "Mean_without_outliers")
# Remove unnecessary variables
rm(outliers_info, Q1, Q3, lower_bound, upper_bound, IQR, col_name)
# Print the summary table
print(outliers_summary)
# Process targets again
df_targets <- df %>%
filter(!(Syll %in% c("pre", "post", "", "post_pre", "disfluency", "break", "<p>")))
# NA stats after outlier removal
na_stats_after_outliers <- calculate_na_stats(df_targets, columns_to_process)
print(na_stats_after_outliers)
rm(columns_to_process)
