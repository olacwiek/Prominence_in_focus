ungroup()
df %>%
arrange(Syll_num) %>%
mutate(
prev_syll = lag(Syll),
next_syll = lead(Syll),
prev_syll_num = lag(Syll_num),
next_syll_num = lead(Syll_num)
) %>%
filter(Syll != "pre" & Syll != "post_pre") %>%
group_by(Syll) %>%
summarize(
avg_prev_duration = mean(duration[prev_syll == "pre" | prev_syll == "post_pre"], na.rm = TRUE),
avg_duration = mean(duration),
avg_next_duration = mean(duration[next_syll == "post" | next_syll == "post_pre"], na.rm = TRUE)
) %>%
ungroup()
df %>%
arrange(Syll_num) %>%
mutate(
prev_duration = lag(duration, order_by = Syll_num),
next_duration = lead(duration, order_by = Syll_num)
) %>%
group_by(Syll) %>%
summarize(
avg_prev_duration = mean(prev_duration[lag(Syll) %in% c("pre", "post_pre")]),
avg_curr_duration = mean(duration),
avg_next_duration = mean(next_duration[lead(Syll) %in% c("post", "post_pre")])
) %>%
ungroup()
df %>%
arrange(Syll_num) %>%
mutate(
prev_duration_1 = lag(duration, order_by = Syll_num),
prev_duration_2 = lag(duration, 2, order_by = Syll_num),
next_duration_1 = lead(duration, order_by = Syll_num),
next_duration_2 = lead(duration, 2, order_by = Syll_num)
) %>%
group_by(Syll) %>%
summarize(
avg_prev_duration_1 = mean(prev_duration_1[lag(Syll) %in% c("pre", "post_pre")]),
avg_prev_duration_2 = mean(prev_duration_2[lag(Syll, 2) %in% c("pre", "post_pre")]),
avg_curr_duration = mean(duration),
avg_next_duration_1 = mean(next_duration_1[lead(Syll) %in% c("post", "post_pre")]),
avg_next_duration_2 = mean(next_duration_2[lead(Syll, 2) %in% c("post", "post_pre")])
) %>%
ungroup()
df %>%
arrange(Syll_num) %>%
group_by(Syll) %>%
mutate(
prev_duration = case_when(
Syll %in% c("pre", "post_pre") ~ lag(duration),
TRUE ~ lag(duration, 2)
),
next_duration = case_when(
Syll %in% c("post", "post_pre") ~ lead(duration),
TRUE ~ lead(duration, 2)
)
) %>%
summarize(
avg_prev_duration = mean(prev_duration, na.rm = TRUE),
avg_curr_duration = mean(duration),
avg_next_duration = mean(next_duration, na.rm = TRUE)
) %>%
ungroup()
df %>%
arrange(Syll_num) %>%
group_by(Syll) %>%
mutate(
prev_duration = case_when(
Syll %in% c("pre", "post_pre") ~ lag(duration),
TRUE ~ lag(duration, 2)
),
next_duration = case_when(
Syll %in% c("post", "post_pre") ~ lead(duration),
TRUE ~ lead(duration, 2)
)
) %>%
summarize(
avg_prev_duration = mean(prev_duration, na.rm = TRUE),
avg_curr_duration = mean(duration),
avg_next_duration = mean(next_duration, na.rm = TRUE)
) %>%
ungroup() %>%
print(n = 100)
df %>%
arrange(Syll_num)
df %>%
arrange(Syll_num) %>%
group_by(Syll)
View(final_result)
View(outliers_summary)
df <- final_result %>%
filter(Item_type == "target")
# Columns to process
columns_to_process <- c("duration", "F0_mean", "F0_max", "F0_min", #"F0_range",
"env_mean", "env_max", "env_min"#, "env_range"
)
# Initialize a list to store outlier information
outliers_info <- list()
# Loop through each column
for (col_name in columns_to_process) {
cat("Processing column:", col_name, "\n")
# Calculate IQR
Q1 <- quantile(df[[col_name]], 0.25, na.rm = TRUE)
Q3 <- quantile(df[[col_name]], 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Define lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Identify outliers
outliers <- df[[col_name]] < lower_bound | df[[col_name]] > upper_bound
# Get outlier information
outliers_info[[col_name]] <- list(
N_outliers = sum(outliers, na.rm = TRUE),
Prop_outliers = (sum(outliers, na.rm = TRUE) / length(df[[col_name]])) * 100,
Mean_outliers = mean(df[[col_name]][outliers], na.rm = TRUE),
Mean_with_outliers = mean(df[[col_name]], na.rm = TRUE),
Mean_without_outliers = mean(df[[col_name]][!outliers], na.rm = TRUE)
)
# Replace outliers with NA
df[[col_name]][outliers] <- NA
}
# Create a summary table
outliers_summary <- data.frame(t(sapply(outliers_info, unlist)))
colnames(outliers_summary) <- c("N_outliers", "Prop_outliers", "Mean_outliers", "Mean_with_outliers", "Mean_without_outliers")
# Remove unnecessary variables
rm(columns_to_process, outliers_info, Q1, Q3, lower_bound, upper_bound, IQR, col_name)
# Print the summary table
print(outliers_summary)
df <- final_result %>%
filter(Item_type == "target")
# Columns to process
columns_to_process <- c("duration", "F0_mean", "F0_max", "F0_min", "F0_range",
"env_mean", "env_max", "env_min", "env_range"
)
# Initialize a list to store outlier information
outliers_info <- list()
# Loop through each column
for (col_name in columns_to_process) {
cat("Processing column:", col_name, "\n")
# Calculate IQR
Q1 <- quantile(df[[col_name]], 0.25, na.rm = TRUE)
Q3 <- quantile(df[[col_name]], 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Define lower and upper bounds for outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Identify outliers
outliers <- df[[col_name]] < lower_bound | df[[col_name]] > upper_bound
# Get outlier information
outliers_info[[col_name]] <- list(
N_outliers = sum(outliers, na.rm = TRUE),
Prop_outliers = (sum(outliers, na.rm = TRUE) / length(df[[col_name]])) * 100,
Mean_outliers = mean(df[[col_name]][outliers], na.rm = TRUE),
Mean_with_outliers = mean(df[[col_name]], na.rm = TRUE),
Mean_without_outliers = mean(df[[col_name]][!outliers], na.rm = TRUE)
)
# Replace outliers with NA
df[[col_name]][outliers] <- NA
}
# Create a summary table
outliers_summary <- data.frame(t(sapply(outliers_info, unlist)))
colnames(outliers_summary) <- c("N_outliers", "Prop_outliers", "Mean_outliers", "Mean_with_outliers", "Mean_without_outliers")
# Remove unnecessary variables
rm(columns_to_process, outliers_info, Q1, Q3, lower_bound, upper_bound, IQR, col_name)
# Print the summary table
print(outliers_summary)
View(df)
View(df_targets)
ggplot(df_targets, aes(x = Language, y = duration, fill = Focus)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "Duration",
fill = "Prosodic Prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
ggplot(df_targets, aes(x = Language, y = duration, fill = Focus)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
title = "Duration of Prosodic Prominence Ratings by Language",
x = "Language",
y = "Duration",
fill = "Prosodic Prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
## z-scored F0
ggplot(df_targets, aes(x = Language, y = F0_mean_z, fill = Focus)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
title = "F0 means of Prosodic Prominence Ratings by Language",
x = "Language",
y = "F0 (z-scored)",
fill = "Prosodic Prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
## z-scored env
ggplot(df_targets, aes(x = Language, y = env_mean_z, fill = Focus)) +
geom_violin(scale = "width", trim = FALSE, alpha = 0.3) +
geom_boxplot(width = 0.1, outlier.shape = NA, position = position_dodge(width = 0.9), alpha = 0.5) +
labs(
title = "ENV means of Prosodic Prominence Ratings by Language",
x = "Language",
y = "ENV (z-scored)",
fill = "Prosodic Prominence"
) +
scale_fill_manual(values = colorBlindBlack8) +
theme_minimal()
wavFiles <- list.files(data, pattern = "\\.wav$", full.names = TRUE)
# This is the tier we will be cutting from
targetTier <- "Label"
# Generate the corresponding TextGrid file name
textGridFile <- sub("\\.wav$", ".TextGrid", wavFiles[1])
# Read the TextGrid file
tg <- readtextgrid::read_textgrid(textGridFile)
# Get the tier specified as input
tier <- tg[tg$tier_name == targetTier, ]
View(tier)
interval <- tier[2, ]
View(interval)
startTime <- interval$xmin - 1
wavFiles <- list.files(data, pattern = "\\.wav$", full.names = TRUE)
# This is the tier we will be cutting from
targetTier <- "Label"
for (wavFile in wavFiles) {
# Generate the corresponding TextGrid file name
textGridFile <- sub("\\.wav$", ".TextGrid", wavFile)
# Check if the TextGrid file exists
if (file.exists(textGridFile)) {
# Read the TextGrid file
tg <- readtextgrid::read_textgrid(textGridFile)
# Get the tier specified as input
tier <- tg[tg$tier_name == targetTier, ]
# Loop through intervals and save corresponding parts of the .wav file
for (i in 1:nrow(tier)) {
interval <- tier[i, ]
# Look if string is text begins with C or G that is followed by a digit
if (str_detect(interval$text, "^(C|G)\\d")) {
startTime <- interval$xmin - 1
endTime <- interval$xmax + 1
# Define the output file name
outputFile <- paste0(audiodata, interval$text, ".wav")
# Check if the file already exists
if (!file.exists(outputFile)) {
# Read the .wav file
audio <- readWave(wavFile, from = startTime, to = endTime, units = "seconds")
# Convert stereo to mono
audio <- mono(audio)
# Write the .wav file
writeWave(audio, file = outputFile)
# Remove unnecessary variables from memory
rm(audio)
} else {
cat("File", outputFile, "already exists. Skipping.\n")
}
# Remove unnecessary variables from memory
rm(startTime, endTime, outputFile)
}
}
# Remove the TextGrid object from memory
rm(tg)
}
}
rm(startTime, endTime, outputFile, tg, i)
writeTextGrid <- function(data, outputFile) {
# Open a connection to the output file
con <- file(outputFile, "w")
# Write the TextGrid header
cat('File type = "ooTextFile"\n', file = con)
cat('Object class = "TextGrid"\n', file = con)
cat('\n', file = con)  # Add an extra line
cat('xmin = 0 \n', file = con)
cat('xmax =', max(data$xmax), '\n', file = con)
cat('tiers? <exists> \n', file = con)
cat('size =', n_distinct(data$tier_name), '\n', file = con)
cat('item []:', '\n', file = con)
# Write the tier information
tiers <- unique(data[, c("tier_num", "tier_name", "tier_type")])
for (i in 1:nrow(tiers)) {
cat(paste0('    item [', i, ']:\n'), file = con)
cat(paste0('        class = "', tiers$tier_type[i], '"\n'), file = con)
cat(paste0('        name = "', tiers$tier_name[i], '"\n'), file = con)
cat(paste0('        xmin = 0\n'), file = con)
cat(paste0('        xmax = ', max(data$xmax), '\n'), file = con)
# Write intervals or points
if (tiers$tier_type[i] == "IntervalTier") {
intervals <- data[data$tier_name == tiers$tier_name[i], ]
cat(paste0('        intervals: size = ', nrow(intervals), '\n'), file = con)
for (j in 1:nrow(intervals)) {
cat(paste0('        intervals [', j, ']:\n'), file = con)
cat(paste0('            xmin = ', intervals$xmin[j], '\n'), file = con)
cat(paste0('            xmax = ', intervals$xmax[j], '\n'), file = con)
cat(paste0('            text = "', intervals$text[j], '"\n'), file = con)
}
} else if (tiers$tier_type[i] == "PointTier") {
points <- data[data$tier_name == tiers$tier_name[i], ]
cat(paste0('        points: size = ', nrow(points), '\n'), file = con)
for (j in 1:nrow(points)) {
cat(paste0('        points [', j, ']:\n'), file = con)
cat(paste0('            number = ', j - 1, '\n'), file = con)  # Point numbers start from 0
cat(paste0('            time = ', points$xmax[j], '\n'), file = con)  # Assuming xmax as time
cat(paste0('            mark = "', points$text[j], '"\n'), file = con)
}
}
}
# Close the connection
close(con)
}
# Loop through WAV files
for (wavFile in wavFiles) {
# Generate the corresponding TextGrid file name
textGridFile <- sub("\\.wav$", ".TextGrid", wavFile)
# Check if the TextGrid file exists
if (file.exists(textGridFile)) {
# Read the original TextGrid file
originalTg <- readtextgrid::read_textgrid(textGridFile)
# Get the tier specified as input
tier <- originalTg[originalTg$tier_name == targetTier, ]
# Loop through intervals and annotations and add them to the new TextGrid
for (i in 1:nrow(tier)) {
interval <- tier[i, ]
# Check if interval$text starts with "G" or "C"
if (str_detect(interval$text, "^(C|G)\\d")) {
startTime <- interval$xmin - 1
endTime <- interval$xmax + 1
# Check if the new TextGrid file already exists
newTgFile <- file.path(paste0(audiodata, interval$text, ".TextGrid"))
if (!file.exists(newTgFile)) {
# Find the corresponding annotations in the original TextGrid
originalAnnotations <- originalTg[originalTg$xmin >= startTime & originalTg$xmax <= endTime, ]
# Ensure that all tiers from originalTg are present in newTgData
missingTiers <- setdiff(unique(originalTg$tier_name), unique(originalAnnotations$tier_name))
# Initialize newTgData as an empty data frame
newTgData <- data.frame()
for (tier_name in missingTiers) {
# Find corresponding intervals in the original TextGrid for missing tiers
originalIntervals <- originalTg[originalTg$tier_name == tier_name, ]
# Add missing tiers to newTgData with adjusted time
newTgData <- rbind(newTgData, mutate(originalIntervals,
xmin = xmin - startTime,
xmax = xmax - startTime))
# Filter rows where xmin is smaller than or equal to zero
newTgData <- newTgData %>% filter(xmin <= 0)
# Keep only the row with the largest xmin value if there are multiple rows
newTgData <- newTgData %>%
group_by(tier_name) %>%
filter(xmin == max(xmin)) %>%
ungroup()
}
# Time normalization missing tiers
newTgData$xmin <- 0
newTgData$xmax <- max(originalAnnotations$xmax) - startTime
# Copy annotations from originalAnnotations
newTgData <- rbind(newTgData, mutate(originalAnnotations,
xmin = xmin - startTime,
xmax = xmax - startTime))
# Time normalization global
newTgData$tier_xmin <- 0
newTgData$tier_xmax <- max(originalAnnotations$xmax) - startTime
# Sort by tier_num
newTgData <- newTgData %>% arrange(tier_num, xmin)
# Check if there is data to write
if (nrow(newTgData) > 0) {
# Save the new TextGrid data as a TextGrid file
writeTextGrid(newTgData, newTgFile)
}
}
}
}
}
}
# Remove unnecessary variables from memory
rm(interval, startTime, endTime, newTgFile, originalAnnotations, originalIntervals, missingTiers, newTgData, tier, wavFile, wavFiles)
rm(originalTg)
rm(targetTier)
rm(targetTier, tier_name, i)
# List of the WAV files
list_wavs <- list.files(audiodata, pattern = ".wav")
# Function to map focus characters to focus values
mapFocus <- function(char) {
switch(char,
I = "information",
C = "contrastive",
R = "corrective",
B = "background",
F = "filler",
"unknown")
}
# Initialize an empty dataframe to store the metadata
META <- data.frame(File = character(),
Language = character(),
Participant = numeric(),
Item_type = character(),
Item_num = numeric(),
Focus = character(),
stringsAsFactors = FALSE)
# Loop through the WAV file names and decode the information
for (wavFile in list_wavs) {
# Split the file name using "_"
parts <- strsplit(wavFile, "_")[[1]]
# Extract the relevant parts
File <- sub("\\.wav$", "", wavFile)
Language <- if (startsWith(parts[1], "G")) "German" else "Catalan"
Participant <- as.numeric(parse_number(parts[1]))
Item_type <- if (parts[2] == "P") "practice" else "target"
Item_num <- as.numeric(parts[3])
Focus <- mapFocus(substr(parts[4], 1, 1))  # Extract the first character
# Create a data frame for the current file
file_meta <- data.frame(File, Language, Participant, Item_type, Item_num, Focus)
# Append the file metadata to META
META <- rbind(META, file_meta)
# Remove unnecessary variables from memory
rm(parts, File, Language, Participant, Item_type, Item_num, Focus, file_meta)
}
View(META)
# List of the WAV files
list_wavs <- list.files(audiodata, pattern = ".wav")
# Function to map focus characters to focus values
mapFocus <- function(char) {
switch(char,
I = "information",
C = "contrastive",
R = "corrective",
B = "background",
F = "filler",
"unknown")
}
# Initialize an empty dataframe to store the metadata
META <- data.frame(File = character(),
Language = character(),
Participant = numeric(),
Item_type = character(),
Item_num = numeric(),
Focus = character(),
stringsAsFactors = FALSE)
# Loop through the WAV file names and decode the information
for (wavFile in list_wavs) {
# Split the file name using "_"
parts <- strsplit(wavFile, "_")[[1]]
# Extract the relevant parts
File <- sub("\\.wav$", "", wavFile)
Language <- if (startsWith(parts[1], "G")) "German" else "Catalan"
Participant <- as.numeric(parse_number(parts[1]))
Item_type <- if (parts[2] == "P") "practice" else "target"
Item_num <- as.numeric(parts[3])
Focus <- mapFocus(substr(parts[4], 1, 1))  # Extract the first character
# Create a data frame for the current file
file_meta <- data.frame(File, Language, Participant, Item_type, Item_num, Focus)
# Append the file metadata to META
META <- rbind(META, file_meta)
# Remove unnecessary variables from memory
rm(parts, File, Language, Participant, Item_type, Item_num, Focus, file_meta)
}
# Remove unnecessary variables from memory
rm(parts, File, Language, Participant, Item_type, Item_num, Focus, file_meta, wavFile, list_wavs)
# Process participant_info so that participant number column is only number
participant_info$Participant <- parse_number(participant_info$Participant)
View(participant_info)
# Set whether to overwrite existing files
overwrite <- FALSE
# List of the WAV files
list_wavs <- list.files(audiodata, pattern = ".wav")
# Processing settings
resample_rate <- 100 # Hz
smoothing <- 5 # 5Hz low-pass Hanning (the lower the value, the smoother)
##################### Main function to extract smoothed envelope ###############################
amplitude_envelope.extract <- function(locationsound, smoothingHz, resampledHz) {
# Read the sound file into R
snd <- rPraat::snd.read(locationsound)
# Apply the Hilbert transform to the signal
hilb <- seewave::hilbert(snd$sig, f = snd$fs, fftw = FALSE)
# Apply complex modulus
env <- as.vector(abs(hilb))
# Smooth with a Hanning window
env_smoothed <- dplR::hanning(x = env, n = snd$fs / smoothingHz)
# Set undeterminable values at the beginning and end to NA and then to 0
env_smoothed[is.na(env_smoothed)] <- 0
# Resample settings at the desired sampling rate
f <- approxfun(1:(snd$duration * snd$fs), env_smoothed)
# Resample
downsampled <- f(seq(from = 0, to = snd$duration * snd$fs, by = snd$fs / resampledHz))
# Return the downsampled smoothed amplitude envelope
return(downsampled[!is.na(downsampled)])
}
# Loop through soundfile locations
for (wav in list_wavs) {
# Do not run this when these files are already generated and overwrite is not set to TRUE
if ((!file.exists(paste0(dataworkspace, substr(wav, 1, nchar(wav) - 4), "_ENV", ".csv"))) & (overwrite != TRUE)) {
# Location of the current sound file in the loop
locsound <- paste0(audiodata, wav)
# Get the amplitude envelope at location, 5Hz Hanning, 100Hz sampling
env <- amplitude_envelope.extract(locsound, smoothing, resample_rate)
# Make a time vector based on the sampling rate (1000/Hz)
time_ms <- seq(1000 / resample_rate, length(env) * (1000 / resample_rate), by = 1000 / resample_rate)
# Bind into a data frame
ENV <- cbind.data.frame(time_ms, env)
# Save it to a folder
write.csv(ENV, file = paste0(dataworkspace, substr(wav, 1, nchar(wav) - 4), "_ENV", ".csv"), row.names = FALSE)
# Remove unnecessary variables from memory
rm(env, time_ms, ENV)
}
}
gc()
