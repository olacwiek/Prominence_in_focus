# Fit the tuned model on the training data
catTuned <- ranger(
y = train_data$percProm,
x = train_data[, 14:52],
num.trees = 5000,
mtry = 3,
min.node.size = 2,
sample.fraction = 0.5980374,
importance = "permutation"
)
catTuned <- ranger(
y = train_data$percProm,
x = train_data[,14:52],
num.trees = 5000,
mtry = 3, # Set the recommended mtry value (number of features).
min.node.size = 2, # Set the recommended min.node.size value (number of samples before a node terminates).
sample.fraction = 0.5980374, # Set the recommended sample fraction value.(% of data for bagging).
importance = "permutation" # Permutation is a computationally intensive test.
)
predictions <- predict(catTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$percProm)
# Print the confusion matrix
print(confusion_matrix)
catTuned
# Calculate feature importance
feature_importance <- importance(catTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance$Feature <- rownames(feature_importance)
colnames(feature_importance) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance[order(-feature_importance$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
# First, impute missing values for columns 13 to 52 in data_prepost_cat
data_prepost_cat_clean <- data_prepost_cat
# Define the modes function
modes <- function(x) {
uniq_x <- unique(x)
uniq_x[which.max(tabulate(match(x, uniq_x)))]
}
# Imputation by mean grouped by language, participant, and focus
data_prepost_cat_clean <- data_prepost_cat_clean %>%
group_by(language, participant, focus) %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))) %>%
mutate(across(where(is.character), ~ ifelse(is.na(.), as.character(modes(.)), .))) %>%
ungroup()
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_prepost_cat_clean), 0.7 * nrow(data_prepost_cat_clean)) # 70% training, 30% testing
train_data <- data_prepost_cat_clean[sample_indices, ]
test_data <- data_prepost_cat_clean[-sample_indices, ]
# Create a classification task for tuning
tunecat <- makeClassifTask(data = train_data[, 13:52], target = "percProm")
View(data_prepost_cat_clean)
# First, impute missing values for columns 13 to 52 in data_prepost_cat
data_prepost_cat_clean <- data_prepost_cat
# Define the modes function
modes <- function(x) {
uniq_x <- unique(x)
uniq_x[which.max(tabulate(match(x, uniq_x)))]
}
# Imputation by mean grouped by language, participant
data_prepost_cat_clean <- data_prepost_cat_clean %>%
group_by(language, participant) %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))) %>%
mutate(across(where(is.character), ~ ifelse(is.na(.), as.character(modes(.)), .))) %>%
ungroup()
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_prepost_cat_clean), 0.7 * nrow(data_prepost_cat_clean)) # 70% training, 30% testing
train_data <- data_prepost_cat_clean[sample_indices, ]
test_data <- data_prepost_cat_clean[-sample_indices, ]
# Create a classification task for tuning
tunecat <- makeClassifTask(data = train_data[, 13:52], target = "percProm")
# Tune the model
tunecat <- tuneRanger(tunecat, measure = list(multiclass.brier), num.trees = 500)
# Return hyperparameter values
tunecat
# Fit the tuned model on the training data
catTuned <- ranger(
y = train_data$percProm,
x = train_data[, 14:52],
num.trees = 5000,
mtry = 7,
min.node.size = 2,
sample.fraction = 0.6591202,
importance = "permutation"
)
# Predict on the test data
predictions <- predict(catTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$percProm)
# Print the confusion matrix
print(confusion_matrix)
catTuned
# Calculate feature importance
feature_importance <- importance(catTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance_df <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance_df$Feature <- rownames(feature_importance_df)
colnames(feature_importance_df) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance_df[order(-feature_importance_df$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
stopCluster(cl)
# Function to apply MICE within each group with detailed logging
impute_group <- function(df) {
if (nrow(df) > 1) {
tryCatch({
imputed <- mice(df, m = 5, method = 'pmm', seed = 998, printFlag = FALSE)
complete_data <- complete(imputed)
return(complete_data)
}, error = function(e) {
message("Error in MICE imputation: ", e)
return(df)  # Return original data if imputation fails
})
} else {
# If not enough rows, return the original data frame
return(df)
}
}
# Split data by language and participant
data_prepost_cat_clean <- data_prepost_cat %>%
group_by(language, participant) %>%
group_split()
# Apply imputation to each group and combine the results
imputed_data_list <- lapply(data_prepost_cat_clean, impute_group)
imputed_data <- bind_rows(imputed_data_list)
# Check for any remaining NAs in the dataset
na_columns_after_imputation <- sapply(imputed_data, function(x) sum(is.na(x)))
na_columns_after_imputation <- na_columns_after_imputation[na_columns_after_imputation > 0]
# Print the columns with remaining NA values (if any) and the number of NA values in each
print(na_columns_after_imputation)
# If there are still NAs, apply mice again on the combined dataset
if (length(na_columns_after_imputation) > 0) {
# Apply MICE imputation again on the combined dataset
imputed <- mice(imputed_data, m = 5, method = 'pmm', seed = 998, printFlag = FALSE)
imputed_data <- complete(imputed)
# Remove intermediate MICE object
rm(imputed)
}
# Check again for any remaining NAs in the dataset
na_columns_final_check <- sapply(imputed_data, function(x) sum(is.na(x)))
na_columns_final_check <- na_columns_final_check[na_columns_final_check > 0]
# Print the columns with remaining NA values (if any) and the number of NA values in each
print(na_columns_final_check)
View(data_prepost_cat_clean)
# Complete the dataset
data_prepost_cat_clean <- imputed_data
View(data_prepost_cat_clean)
# Remove the final imputed data frame to clean up environment
rm(imputed_data, na_columns_final_check, imputed_data_list, na_columns_after_imputation)
set.seed(998)
# Split the data into training and testing subsets
sample_indices <- sample(1:nrow(data_prepost_cat_clean), 0.7 * nrow(data_prepost_cat_clean)) # 70% training, 30% testing
train_data <- data_prepost_cat_clean[sample_indices, ]
test_data <- data_prepost_cat_clean[-sample_indices, ]
# Create a classification task for tuning
tunecat <- makeClassifTask(data = train_data[, 13:52], target = "percProm")
# Tune the model
tunecat <- tuneRanger(tunecat, measure = list(multiclass.brier), num.trees = 500)
# Return hyperparameter values
tunecat
# Fit the tuned model on the training data
catTuned <- ranger(
y = train_data$percProm,
x = train_data[, 14:52],
num.trees = 5000,
mtry = 8,
min.node.size = 2,
sample.fraction = 0.5820302,
importance = "permutation"
)
# Predict on the test data
predictions <- predict(catTuned, data = test_data)$predictions
# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$percProm)
# Print the confusion matrix
print(confusion_matrix)
catTuned
# Calculate feature importance
feature_importance <- importance(catTuned, num.threads = 1, type = 1)
# Convert to data frame
feature_importance_df <- as.data.frame(feature_importance, stringsAsFactors = FALSE)
feature_importance_df$Feature <- rownames(feature_importance_df)
colnames(feature_importance_df) <- c("Importance", "Feature")
# Sort by importance
sorted_feature_importance <- feature_importance_df[order(-feature_importance_df$Importance), ]
# Print sorted feature importance
print(sorted_feature_importance)
write.csv(data_prepost_cat_clean, file = paste0(datasets, "catDataXGB.csv"), row.names = FALSE)
# Detect the number of available cores
cores <- detectCores() - 1  # Leave one core free
# Create a cluster with the detected number of cores
cl <- makeCluster(cores)
# Register the parallel backend
registerDoParallel(cl)
grid_tune <- expand.grid(
nrounds = c(5000, 10000),
max_depth = c(3, 6),
eta = c(0.05, 0.1),
gamma = c(0.1),
colsample_bytree = c(0.6, 0.8),
min_child_weight = c(1),
subsample = c(0.75, 1.0)
)
# Set seed for reproducibility
set.seed(998)
# Set up train control
train_control <- trainControl(
method = "cv",        # Cross-validation
number = 5,           # 5-fold cross-validation
allowParallel = TRUE  # Enable parallel processing
)
# Define the number of subsets
numSubsets <- 5
# Create an empty list to store subsets
catSubsets <- vector("list", length = numSubsets)
# only keep the columns of output and predictor variables
catDataXGB <- read_csv(paste0(datasets, "catDataXGB.csv")) # load MICE imputed data
catDataXGB <- catDataXGB[,13:52]
head(catDataXGB)
# Calculate the number of samples in each subset
subsetSize <- nrow(catDataXGB) %/% numSubsets
# Randomly assign samples to subsets
for (i in 1:numSubsets) {
if (i < numSubsets) {
catSubsets[[i]] <- catDataXGB[sample((1:nrow(catDataXGB)), size = subsetSize), ]
} else {
catSubsets[[i]] <- catDataXGB[sample((1:nrow(catDataXGB)), size = subsetSize + (nrow(catDataXGB) %% numSubsets)), ]
}
}
# Naming the subsets
names(catSubsets) <- paste0("catData", 1:numSubsets)
# Access the subsets (e.g., catData1, catData2, etc.)
catData1 <- catSubsets$catData1
catData2 <- catSubsets$catData2
catData3 <- catSubsets$catData3
catData4 <- catSubsets$catData4
catData5 <- catSubsets$catData5
# Combine subsets into 80% groups.
catData1234 <- rbind(catData1, catData2, catData3, catData4)
catData1235 <- rbind(catData1, catData2, catData3, catData5)
catData1245 <- rbind(catData1, catData2, catData4, catData5)
catData1345 <- rbind(catData1, catData3, catData4, catData5)
catData2345 <- rbind(catData2, catData3, catData4, catData5)
catModel1 <- caret::train(
percProm ~ .,
data = catData1234,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
# Detect the number of available cores
cores <- detectCores() #- 1  # Leave one core free
# Create a cluster with the detected number of cores
cl <- makeCluster(cores)
# Register the parallel backend
registerDoParallel(cl)
catModel1 <- caret::train(
percProm ~ .,
data = catData1234,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel1, file = paste0(models, "catModel1.rds"), compress = TRUE)
catModel2 <- caret::train(
percProm ~ .,
data = catData1235,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel2, file = paste0(models, "catModel2.rds"), compress = TRUE)
catModel3 <- caret::train(
percProm ~ .,
data = catData1245,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel3, file = paste0(models, "catModel3.rds"), compress = TRUE)
catModel4 <- caret::train(
percProm ~ .,
data = catData1345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel4, file = paste0(models, "catModel4.rds"), compress = TRUE)
catModel5 <- caret::train(
percProm ~ .,
data = catData2345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel5, file = paste0(models, "catModel5.rds"), compress = TRUE)
# Generate predictions
catPredictions1 <- predict(catModel1, newdata = catData5)
catPredictions2 <- predict(catModel2, newdata = catData4)
catPredictions3 <- predict(catModel3, newdata = catData3)
catPredictions4 <- predict(catModel4, newdata = catData2)
catPredictions5 <- predict(catModel5, newdata = catData1)
# Compute confusion matrices
catCm1 <- confusionMatrix(catPredictions1, catData5$percProm)
catPredictions1
catModel1
# Compute confusion matrices
catCm1 <- confusionMatrix(catPredictions1, catData5$percProm)
catCm2 <- confusionMatrix(catPredictions2, catData4$percProm)
catCm3 <- confusionMatrix(catPredictions3, catData3$percProm)
catCm4 <- confusionMatrix(catPredictions4, catData2$percProm)
catCm5 <- confusionMatrix(catPredictions5, catData1$percProm)
levels(catData1$percProm)
str(catData1$percProm)
# Detect the number of available cores
cores <- detectCores() #- 1  # Leave one core free
# Create a cluster with the detected number of cores
cl <- makeCluster(cores)
# Register the parallel backend
registerDoParallel(cl)
grid_tune <- expand.grid(
nrounds = c(5000, 10000),
max_depth = c(3, 6),
eta = c(0.05, 0.1),
gamma = c(0.1),
colsample_bytree = c(0.6, 0.8),
min_child_weight = c(1),
subsample = c(0.75, 1.0)
)
# Set seed for reproducibility
set.seed(998)
# Set up train control
train_control <- trainControl(
method = "cv",        # Cross-validation
number = 5,           # 5-fold cross-validation
allowParallel = TRUE  # Enable parallel processing
)
# Define the number of subsets
numSubsets <- 5
# Create an empty list to store subsets
catSubsets <- vector("list", length = numSubsets)
# load MICE imputed data
catDataXGB <- read_csv(paste0(datasets, "catDataXGB.csv"))
# ensure percProm is factor
catDataXGB$percProm <- as.factor(catDataXGB$percProm)
str(catDataXGB)
levels(catDataXGB$percProm)
# only keep the columns of output and predictor variables
catDataXGB <- catDataXGB[,13:52]
# Calculate the number of samples in each subset
subsetSize <- nrow(catDataXGB) %/% numSubsets
# Randomly assign samples to subsets
for (i in 1:numSubsets) {
if (i < numSubsets) {
catSubsets[[i]] <- catDataXGB[sample((1:nrow(catDataXGB)), size = subsetSize), ]
} else {
catSubsets[[i]] <- catDataXGB[sample((1:nrow(catDataXGB)), size = subsetSize + (nrow(catDataXGB) %% numSubsets)), ]
}
}
# Naming the subsets
names(catSubsets) <- paste0("catData", 1:numSubsets)
# Access the subsets (e.g., catData1, catData2, etc.)
catData1 <- catSubsets$catData1
catData2 <- catSubsets$catData2
catData3 <- catSubsets$catData3
catData4 <- catSubsets$catData4
catData5 <- catSubsets$catData5
# Combine subsets into 80% groups.
catData1234 <- rbind(catData1, catData2, catData3, catData4)
catData1235 <- rbind(catData1, catData2, catData3, catData5)
catData1245 <- rbind(catData1, catData2, catData4, catData5)
catData1345 <- rbind(catData1, catData3, catData4, catData5)
catData2345 <- rbind(catData2, catData3, catData4, catData5)
catModel1 <- caret::train(
percProm ~ .,
data = catData1234,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel1, file = paste0(models, "catModel1.rds"), compress = TRUE)
catModel2 <- caret::train(
percProm ~ .,
data = catData1235,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel2, file = paste0(models, "catModel2.rds"), compress = TRUE)
catModel3 <- caret::train(
percProm ~ .,
data = catData1245,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel3, file = paste0(models, "catModel3.rds"), compress = TRUE)
catModel4 <- caret::train(
percProm ~ .,
data = catData1345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel4, file = paste0(models, "catModel4.rds"), compress = TRUE)
# Generate predictions
catPredictions1 <- predict(catModel1, newdata = catData5)
# Compute confusion matrices
catCm1 <- confusionMatrix(catPredictions1, catData5$percProm)
catCm1
catModel5 <- caret::train(
percProm ~ .,
data = catData2345,
method = "xgbTree",
trControl = train_control,
tuneGrid = grid_tune
)
saveRDS(catModel5, file = paste0(models, "catModel5.rds"), compress = TRUE)
# Generate predictions
catPredictions1 <- predict(catModel1, newdata = catData5)
catPredictions2 <- predict(catModel2, newdata = catData4)
catPredictions3 <- predict(catModel3, newdata = catData3)
catPredictions4 <- predict(catModel4, newdata = catData2)
catPredictions5 <- predict(catModel5, newdata = catData1)
# Compute confusion matrices
catCm1 <- confusionMatrix(catPredictions1, catData5$percProm)
catCm2 <- confusionMatrix(catPredictions2, catData4$percProm)
catCm3 <- confusionMatrix(catPredictions3, catData3$percProm)
catCm4 <- confusionMatrix(catPredictions4, catData2$percProm)
catCm5 <- confusionMatrix(catPredictions5, catData1$percProm)
# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
catPValues <- c(catCm1$overall['AccuracyPValue'],
catCm2$overall['AccuracyPValue'],
catCm3$overall['AccuracyPValue'],
catCm4$overall['AccuracyPValue'],
catCm5$overall['AccuracyPValue'])
# Fisher's method
catFisher_combined <- -2 * sum(log(catPValues))
df <- 2 * length(catPValues)
catPCcombined_fisher <- 1 - pchisq(catFisher_combined, df)
print(catPCcombined_fisher)
# Stouffer's method
catZ_scores <- qnorm(1 - catPValues/2)
catCombined_z <- sum(catZ_scores) / sqrt(length(catPValues))
catP_combined_stouffer <- 2 * (1 - pnorm(abs(catCombined_z)))
print(catP_combined_stouffer)
XGBcatModel1 <- catModel1$finalModel
importanceXGBcatModel1 <- xgb.importance(model = XGBcatModel1)
print(importanceXGBcatModel1)
xgb.plot.importance(importanceXGBcatModel1)
XGBcatModel2 <- catModel2$finalModel
importanceXGBcatModel2 <- xgb.importance(model = XGBcatModel2)
print(importanceXGBcatModel2)
xgb.plot.importance(importanceXGBcatModel2)
XGBcatModel3 <- catModel3$finalModel
importanceXGBcatModel3 <- xgb.importance(model = XGBcatModel3)
print(importanceXGBcatModel3)
xgb.plot.importance(importanceXGBcatModel3)
XGBcatModel4 <- catModel4$finalModel
importanceXGBcatModel4 <- xgb.importance(model = XGBcatModel4)
print(importanceXGBcatModel4)
xgb.plot.importance(importanceXGBcatModel4)
XGBcatModel5 <- catModel5$finalModel
importanceXGBcatModel5 <- xgb.importance(model = XGBcatModel5)
print(importanceXGBcatModel5)
xgb.plot.importance(importanceXGBcatModel5)
XGBcatModel5 <- catModel5$finalModel
importanceXGBcatModel5 <- xgb.importance(model = XGBcatModel5)
print(importanceXGBcatModel5)
xgb.plot.importance(importanceXGBcatModel5)
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
importance <- xgb.importance(model = model)
importance$Gain <- importance$Gain / sum(importance$Gain)
return(importance)
}
# Extract normalized importance for each model
catImportance1 <- get_normalized_importance(catModel1$finalModel)
catImportance2 <- get_normalized_importance(catModel2$finalModel)
catImportance3 <- get_normalized_importance(catModel3$finalModel)
catImportance4 <- get_normalized_importance(catModel4$finalModel)
catImportance5 <- get_normalized_importance(catModel5$finalModel)
# Combine importances
catAllImportances <- list(catImportance1, catImportance2, catImportance3, catImportance4, catImportance5)
# Function to merge importances
merge_importances <- function(importances) {
for (i in 2:length(importances)) {
names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
}
merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
merged[is.na(merged)] <- 0  # Replace NAs with 0
gain_cols <- grep("Gain", colnames(merged), value = TRUE)
merged$Cumulative <- rowSums(merged[, ..gain_cols])
return(merged[, .(Feature, Cumulative)])
}
# Merge and sort importances
catCumulativeImportance <- merge_importances(catAllImportances)
catCumulativeImportance <- catCumulativeImportance[order(-catCumulativeImportance$Cumulative), ]
# Print cumulative feature importance
print(catCumulativeImportance)
catPredictions1
catCm1
catCm2
catCm3
catCm4
catCm5
# Print cumulative feature importance
print(catCumulativeImportance)
