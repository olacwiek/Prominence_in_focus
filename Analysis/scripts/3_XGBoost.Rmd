---
title: "Acoustic correlates of perceived prominence in German and Catalan: XGBoost Modeling"
author: "Aleksandra Ćwiek, Alina Gregori, Paula G. Sánchez-Ramón, Frank Kügler, Pilar Prieto"
date: "2024-06-20"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
    df_print: paged
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This is the analysis using random forests and XGBoost algorithms.

# Data preparation

## Source setup

```{r source setup, echo = TRUE, message=FALSE, warning = FALSE}

########## folders ##########
# current folder (first go to session -> set working directory -> to source file location)
parentfolder <- dirname(getwd())

data          <- paste0(parentfolder, '/MultIS_data/')
audiodata     <- paste0(parentfolder, '/audio_processed/')
syllables     <- paste0(audiodata,    'syllables/')
dataworkspace <- paste0(parentfolder, '/data_processed/')
datamerged    <- paste0(parentfolder, '/data_merged/')
datasets      <- paste0(parentfolder, '/datasets/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')

########## source file ##########

#source(paste0(scripts, "adjectives-preparation.R"))

#################### packages ####################
# Data Manipulation
library(tibble)
library(stringr)
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
packageVersion("tidyverse")
library(data.table)

# Plotting
library(ggforce)
library(ggpubr)
library(gridExtra)

# Random Forests
library(rpart)
library(rpart.plot)
library(ranger)
library(tuneRanger)
library(caret)
# XGBoost
library(xgboost); packageVersion("xgboost")
library(parallel); packageVersion("parallel")
library(mice); packageVersion("mice")
library(doParallel); packageVersion("doParallel")
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())

colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                       "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

```

## Load in data frames

```{r read metadata, echo=TRUE, message=FALSE, warning=FALSE}
participant_info <- read_delim(paste0(data,"ParticipantInfo_GERCAT.csv"), delim = ";")

# Load the information about duration of each segment (if needed)
data_df <- read.table(paste0(syllables, "fileDurationsDF.csv"), header = TRUE, sep = ',')

# Load cleaned syllable data
data <- read_csv(paste0(datasets, "data_cleaned.csv"))

# Load cleaned targets data
targets <- read_csv(paste0(datasets, "targets.csv"))

# Load cleaned targets with pre-post data
data_prepost <- read_csv(paste0(datasets, "data_prepost.csv"))
```

## You can add participant info

```{r metadata merge, echo=TRUE, message=FALSE, warning=FALSE}
# Process participant_info so that participant number column is only number
participant_info$Participant <- parse_number(participant_info$Participant)

# Merge the dataframes by "Participant" and "Language"
# Exchange META to the dataframe of your liking
# META <- merge(META, participant_info, by = c("Participant", "Language"), all.x = TRUE)

```

# Data preparation

Inspect the data and convert to factors, if needed. Then split in two
languages. We are interested in tonic and pre- and posttonic syllables,
so we take the prepost data.

```{r inspect data, echo=TRUE, message=FALSE, warning=FALSE}
str(data_prepost)

# Turn percProm to factor
data_prepost$percProm <- as.factor(data_prepost$percProm)

# First, remove the specified columns
data_prepost <- data_prepost %>%
  select(-f1_freq_median, -f1_freq_median_norm, -f2_freq_median, -f2_freq_median_norm, 
         -f1_freq_medianPre, -f1_freq_median_normPre, -f2_freq_medianPre, -f2_freq_median_normPre, 
         -f1_freq_medianPost, -f1_freq_median_normPost, -f2_freq_medianPost, -f2_freq_median_normPost,
         -pitch_sd, -pitch_median, -f0_slope, -pitch_sdPre, -pitch_medianPre, -f0_slopePre, 
         -pitch_sdPost, -pitch_medianPost, -f0_slopePost)

# Then, rearrange the remaining columns
data_prepost <- data_prepost %>%
  select(fileName, language, participant, itemType, itemNum, focus, annotationNum, 
         annotationNumTarget, word, syllText, syllTextPre, syllTextPost, percProm, 
         duration, duration_noSilence, 
         ampl_median, ampl_sd, 
         ampl_noSilence_median, ampl_noSilence_sd, 
         env_slope, 
         pitch_median_norm, pitch_sd_norm, 
         f0_slope_norm, 
         CPP_median, CPP_sd, 
         flux_median, flux_sd, 
         novelty_median, novelty_sd, 
         specCentroid_median, specCentroid_sd, 
         entropy_median, entropy_sd, 
         entropySh_median, entropySh_sd, 
         HNR_median, HNR_sd, 
         amEnvDep_median, amEnvDep_sd, 
         fmDep_median, fmDep_sd,
         durationPre, duration_noSilencePre, 
         ampl_medianPre, ampl_sdPre, 
         ampl_noSilence_medianPre, ampl_noSilence_sdPre, 
         env_slopePre, 
         pitch_median_normPre, pitch_sd_normPre, 
         f0_slope_normPre, 
         CPP_medianPre, CPP_sdPre, 
         flux_medianPre, flux_sdPre, 
         novelty_medianPre, novelty_sdPre, 
         specCentroid_medianPre, specCentroid_sdPre, 
         entropy_medianPre, entropy_sdPre, 
         entropySh_medianPre, entropySh_sdPre, 
         HNR_medianPre, HNR_sdPre, 
         amEnvDep_medianPre, amEnvDep_sdPre, 
         fmDep_medianPre, fmDep_sdPre,
         durationPost, duration_noSilencePost, 
         ampl_medianPost, ampl_sdPost, 
         ampl_noSilence_medianPost, ampl_noSilence_sdPost, 
         env_slopePost, 
         pitch_median_normPost, pitch_sd_normPost, 
         f0_slope_normPost, 
         CPP_medianPost, CPP_sdPost, 
         flux_medianPost, flux_sdPost, 
         novelty_medianPost, novelty_sdPost, 
         specCentroid_medianPost, specCentroid_sdPost, 
         entropy_medianPost, entropy_sdPost, 
         entropySh_medianPost, entropySh_sdPost, 
         HNR_medianPost, HNR_sdPost, 
         amEnvDep_medianPost, amEnvDep_sdPost, 
         fmDep_medianPost, fmDep_sdPost)


# Create data_prepost_german for rows where language is German
data_prepost_ger <- data_prepost %>% 
  filter(language == "German")

# Create data_prepost_catalan for rows where language is Catalan
data_prepost_cat <- data_prepost %>% 
  filter(language == "Catalan")
```

## German

### Impute missing data with MICE

MICE (Multiple Imputation by Chained Equations) is a robust method used to handle missing data by generating multiple imputed datasets and then combining the results. It works by iteratively imputing missing values for each variable, using a predictive model based on the other variables in the dataset. This method allows for the uncertainty of missing data by creating several different plausible imputed datasets and combining their results.

To adapt MICE imputation for grouping by language, participant, and focus, we perform the imputation within each group separately. This can be done by splitting the data into groups, applying MICE to each group, and then combining the imputed datasets. This takes a good while.

```{r MICE ger, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
# Function to apply MICE within each group with detailed logging
impute_group <- function(df) {
  if (nrow(df) > 1) {
    tryCatch({
      imputed <- mice(df, m = 5, method = 'pmm', seed = 998, printFlag = FALSE)
      complete_data <- complete(imputed)
      return(complete_data)
    }, error = function(e) {
      message("Error in MICE imputation: ", e)
      return(df)  # Return original data if imputation fails
    })
  } else {
    # If not enough rows, return the original data frame
    return(df)
  }
}

# Split data by language and participant
data_prepost_ger_clean <- data_prepost_ger %>%
  group_by(language, participant) %>%
  group_split()

# Apply imputation to each group and combine the results
imputed_data_list <- lapply(data_prepost_ger_clean, impute_group)
imputed_data <- bind_rows(imputed_data_list)

# Check for any remaining NAs in the dataset
na_columns_after_imputation <- sapply(imputed_data, function(x) sum(is.na(x)))
na_columns_after_imputation <- na_columns_after_imputation[na_columns_after_imputation > 0]

# Print the columns with remaining NA values (if any) and the number of NA values in each
print(na_columns_after_imputation)

# If there are still NAs, apply mice again on the combined dataset
if (length(na_columns_after_imputation) > 0) {
  # Apply MICE imputation again on the combined dataset
  imputed <- mice(imputed_data, m = 5, method = 'pmm', seed = 998, printFlag = FALSE)
  imputed_data <- complete(imputed)
  # Remove intermediate MICE object
  rm(imputed)
}

# Check again for any remaining NAs in the dataset
na_columns_final_check <- sapply(imputed_data, function(x) sum(is.na(x)))
na_columns_final_check <- na_columns_final_check[na_columns_final_check > 0]

# Print the columns with remaining NA values (if any) and the number of NA values in each
print(na_columns_final_check)

# Complete the dataset
data_prepost_ger_clean <- imputed_data

# Remove the final imputed data frame to clean up environment
rm(imputed_data, na_columns_final_check, imputed_data_list, na_columns_after_imputation)

```

Save imputed data frame.

```{r save imputed data, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
write.csv(data_prepost_ger_clean, file = paste0(datasets, "gerDataXGB.csv"), row.names = FALSE)
```

### XGBoost

Ensure parallel processing.

```{r parallel ger, echo=TRUE, message=FALSE, warning=FALSE}
# Detect the number of available cores
cores <- detectCores() #- 1  # Leave one core free

# Create a cluster with the detected number of cores
cl <- makeCluster(cores)

# Register the parallel backend
registerDoParallel(cl)
```

Define the grid and estimate runtime.

```{r grid ger, echo=TRUE, message=FALSE, warning=FALSE}
grid_tune <- expand.grid(
  nrounds = c(5000, 10000), 
  max_depth = c(3, 6), 
  eta = c(0.05, 0.1), 
  gamma = c(0.1), 
  colsample_bytree = c(0.6, 0.8), 
  min_child_weight = c(1), 
  subsample = c(0.75, 1.0)
)

# Calculate total combinations
total_combinations <- nrow(grid_tune)

# Estimate single model run time (assume 1 minute per run)
single_model_time <- 10 # minute

# Total runs for cross-validation
folds <- 5
total_runs <- total_combinations * folds

# Total time estimation without parallel processing
total_time <- total_runs * single_model_time # in minutes

# Convert to hours
total_time_hours <- total_time / 60

# Output estimated time without parallel processing
print(paste("Estimated time for grid search without parallel processing:", total_time_hours, "hours"))

# Parallel processing with 4 cores
cores <- 24
total_time_parallel <- total_time / cores # in minutes

# Convert to hours
total_time_parallel_hours <- total_time_parallel / 60

# Output estimated time with parallel processing
print(paste("Estimated time for grid search with", cores, "cores:", total_time_parallel_hours, "hours"))

rm(total_combinations,single_model_time,folds,total_runs,total_time,total_time_hours,total_time_parallel,total_time_parallel_hours,cores)
```

#### K-fold cross-validation

Create subsets to train and test data (80/20).

```{r k-fold subset ger, echo=TRUE, message=FALSE, warning=FALSE}
# Set seed for reproducibility
set.seed(998)

# Set up train control
train_control <- trainControl(
  method = "cv",        # Cross-validation
  number = 5,           # 5-fold cross-validation
  allowParallel = TRUE  # Enable parallel processing
)

# Define the number of subsets
numSubsets <- 5

# Create an empty list to store subsets
gerSubsets <- vector("list", length = numSubsets)

# load MICE imputed data
gerDataXGB <- read_csv(paste0(datasets, "gerDataXGB.csv"))
# ensure percProm is factor
gerDataXGB$percProm <- as.factor(gerDataXGB$percProm)
levels(gerDataXGB$percProm)
# only keep the columns of output and predictor variables
gerDataXGB <- gerDataXGB[,13:97] 

# Calculate the number of samples in each subset
subsetSize <- nrow(gerDataXGB) %/% numSubsets

# Randomly assign samples to subsets
for (i in 1:numSubsets) {
  if (i < numSubsets) {
    gerSubsets[[i]] <- gerDataXGB[sample((1:nrow(gerDataXGB)), size = subsetSize), ]
  } else {
    gerSubsets[[i]] <- gerDataXGB[sample((1:nrow(gerDataXGB)), size = subsetSize + (nrow(gerDataXGB) %% numSubsets)), ]
  }
}

# Naming the subsets
names(gerSubsets) <- paste0("gerData", 1:numSubsets)

# Access the subsets (e.g., gerData1, gerData2, etc.)
gerData1 <- gerSubsets$gerData1
gerData2 <- gerSubsets$gerData2
gerData3 <- gerSubsets$gerData3
gerData4 <- gerSubsets$gerData4
gerData5 <- gerSubsets$gerData5

# Combine subsets into 80% groups.
gerData1234 <- rbind(gerData1, gerData2, gerData3, gerData4)
gerData1235 <- rbind(gerData1, gerData2, gerData3, gerData5)
gerData1245 <- rbind(gerData1, gerData2, gerData4, gerData5)
gerData1345 <- rbind(gerData1, gerData3, gerData4, gerData5)
gerData2345 <- rbind(gerData2, gerData3, gerData4, gerData5)

```

#### Models

Only run the models one time and then readRDS.

##### Model 1

```{r ger model1, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
gerModel1 <- caret::train(
  percProm ~ .,              
  data = gerData1234,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(gerModel1, file = paste0(models, "gerModel1.rds"), compress = TRUE)
```

##### Model 2

```{r ger model2, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
gerModel2 <- caret::train(
  percProm ~ .,              
  data = gerData1235,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(gerModel2, file = paste0(models, "gerModel2.rds"), compress = TRUE)
```

##### Model 3

```{r ger model3, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
gerModel3 <- caret::train(
  percProm ~ .,              
  data = gerData1245,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(gerModel3, file = paste0(models, "gerModel3.rds"), compress = TRUE)
```

##### Model 4

```{r ger model4, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
gerModel4 <- caret::train(
  percProm ~ .,              
  data = gerData1345,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)
saveRDS(gerModel4, file = paste0(models, "gerModel4.rds"), compress = TRUE)
```

##### Model 5

```{r ger model5, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
gerModel5 <- caret::train(
  percProm ~ .,              
  data = gerData2345,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(gerModel5, file = paste0(models, "gerModel5.rds"), compress = TRUE)
```

##### Load models

Load all models after running, if necessary.

```{r loas models ger, echo=TRUE, message=FALSE, warning=FALSE}
gerModel1 <- readRDS(paste0(models, "gerModel1.rds"))
gerModel2 <- readRDS(paste0(models, "gerModel2.rds"))
gerModel3 <- readRDS(paste0(models, "gerModel3.rds"))
gerModel4 <- readRDS(paste0(models, "gerModel4.rds"))
gerModel5 <- readRDS(paste0(models, "gerModel5.rds"))
```

#### Test models

Generate predictions and confusion matrices

```{r test models ger, echo=TRUE, message=FALSE, warning=FALSE}
# Generate predictions
gerPredictions1 <- predict(gerModel1, newdata = gerData5)
gerPredictions2 <- predict(gerModel2, newdata = gerData4)
gerPredictions3 <- predict(gerModel3, newdata = gerData3)
gerPredictions4 <- predict(gerModel4, newdata = gerData2)
gerPredictions5 <- predict(gerModel5, newdata = gerData1)

# Compute confusion matrices
gerCm1 <- confusionMatrix(gerPredictions1, gerData5$percProm)
gerCm2 <- confusionMatrix(gerPredictions2, gerData4$percProm)
gerCm3 <- confusionMatrix(gerPredictions3, gerData3$percProm)
gerCm4 <- confusionMatrix(gerPredictions4, gerData2$percProm)
gerCm5 <- confusionMatrix(gerPredictions5, gerData1$percProm)

# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
gerPValues <- c(gerCm1$overall['AccuracyPValue'], 
              gerCm2$overall['AccuracyPValue'], 
              gerCm3$overall['AccuracyPValue'], 
              gerCm4$overall['AccuracyPValue'], 
              gerCm5$overall['AccuracyPValue'])
```

Show confusion matrices.

```{r output ger, echo=TRUE, message=FALSE, warning=FALSE}
gerCm1
gerCm2
gerCm3
gerCm4
gerCm5
```

Combine p-values using Fisher's method

```{r combine p-vals ger, echo=TRUE, message=FALSE, warning=FALSE}
# Fisher's method
gerFisher_combined <- -2 * sum(log(gerPValues))
df <- 2 * length(gerPValues)
gerPCcombined_fisher <- 1 - pchisq(gerFisher_combined, df)
print(gerPCcombined_fisher)

# Stouffer's method
gerZ_scores <- qnorm(1 - gerPValues/2)
gerCombined_z <- sum(gerZ_scores) / sqrt(length(gerPValues))
gerP_combined_stouffer <- 2 * (1 - pnorm(abs(gerCombined_z)))
print(gerP_combined_stouffer)
```

The p-values sum up to 0, since they are all so small.

#### Feature importance

##### Model 1

```{r ger feature importance 1, echo=TRUE, message=FALSE, warning=FALSE}
XGBgerModel1 <- gerModel1$finalModel
importanceXGBgerModel1 <- xgb.importance(model = XGBgerModel1)
print(importanceXGBgerModel1)
xgb.plot.importance(importanceXGBgerModel1[1:10,])
```

##### Model 2

```{r ger feature importance 2, echo=TRUE, message=FALSE, warning=FALSE}
XGBgerModel2 <- gerModel2$finalModel
importanceXGBgerModel2 <- xgb.importance(model = XGBgerModel2)
print(importanceXGBgerModel2)
xgb.plot.importance(importanceXGBgerModel2[1:10,])
```

##### Model 3

```{r ger feature importance 3, echo=TRUE, message=FALSE, warning=FALSE}
XGBgerModel3 <- gerModel3$finalModel
importanceXGBgerModel3 <- xgb.importance(model = XGBgerModel3)
print(importanceXGBgerModel3)
xgb.plot.importance(importanceXGBgerModel3[1:10,])
```

##### Model 4

```{r ger feature importance 4, echo=TRUE, message=FALSE, warning=FALSE}
XGBgerModel4 <- gerModel4$finalModel
importanceXGBgerModel4 <- xgb.importance(model = XGBgerModel4)
print(importanceXGBgerModel4)
xgb.plot.importance(importanceXGBgerModel4[1:10,])
```

##### Model 5

```{r ger feature importance 5, echo=TRUE, message=FALSE, warning=FALSE}
XGBgerModel5 <- gerModel5$finalModel
importanceXGBgerModel5 <- xgb.importance(model = XGBgerModel5)
print(importanceXGBgerModel5)
xgb.plot.importance(importanceXGBgerModel5[1:10,])
```

##### Cumulative feature importance

```{r ger cumulative importance, echo=TRUE, message=FALSE, warning=FALSE}
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
  importance <- xgb.importance(model = model)
  importance$Gain <- importance$Gain / sum(importance$Gain)
  return(importance)
}

# Extract normalized importance for each model
gerImportance1 <- get_normalized_importance(gerModel1$finalModel)
gerImportance2 <- get_normalized_importance(gerModel2$finalModel)
gerImportance3 <- get_normalized_importance(gerModel3$finalModel)
gerImportance4 <- get_normalized_importance(gerModel4$finalModel)
gerImportance5 <- get_normalized_importance(gerModel5$finalModel)

# Combine importances
gerAllImportances <- list(gerImportance1, gerImportance2, gerImportance3, gerImportance4, gerImportance5)

# Function to merge importances
merge_importances <- function(importances) {
  for (i in 2:length(importances)) {
    names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
  }
  merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
  merged[is.na(merged)] <- 0  # Replace NAs with 0
  gain_cols <- grep("Gain", colnames(merged), value = TRUE)
  merged$Cumulative <- rowSums(merged[, ..gain_cols])
  return(merged[, .(Feature, Cumulative)])
}

# Merge and sort importances
gerCumulativeImportance <- merge_importances(gerAllImportances)
gerCumulativeImportance <- gerCumulativeImportance[order(-gerCumulativeImportance$Cumulative), ]

# Print cumulative feature importance
print(gerCumulativeImportance)
```

## Catalan

### Impute missing data with MICE

MICE (Multiple Imputation by Chained Equations) is a robust method used to handle missing data by generating multiple imputed datasets and then combining the results. It works by iteratively imputing missing values for each variable, using a predictive model based on the other variables in the dataset. This method allows for the uncertainty of missing data by creating several different plausible imputed datasets and combining their results.

To adapt MICE imputation for grouping by language and participant, we perform the imputation within each group separately. This can be done by splitting the data into groups, applying MICE to each group, and then combining the imputed datasets. This takes a good while.

```{r MICE cat, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
# Function to apply MICE within each group with detailed logging
impute_group <- function(df) {
  if (nrow(df) > 1) {
    tryCatch({
      imputed <- mice(df, m = 5, method = 'pmm', seed = 998, printFlag = FALSE)
      complete_data <- complete(imputed)
      return(complete_data)
    }, error = function(e) {
      message("Error in MICE imputation: ", e)
      return(df)  # Return original data if imputation fails
    })
  } else {
    # If not enough rows, return the original data frame
    return(df)
  }
}

# Split data by language and participant
data_prepost_cat_clean <- data_prepost_cat %>%
  group_by(language, participant) %>%
  group_split()

# Apply imputation to each group and combine the results
imputed_data_list <- lapply(data_prepost_cat_clean, impute_group)
imputed_data <- bind_rows(imputed_data_list)

# Check for any remaining NAs in the dataset
na_columns_after_imputation <- sapply(imputed_data, function(x) sum(is.na(x)))
na_columns_after_imputation <- na_columns_after_imputation[na_columns_after_imputation > 0]

# Print the columns with remaining NA values (if any) and the number of NA values in each
print(na_columns_after_imputation)

# If there are still NAs, apply mice again on the combined dataset
if (length(na_columns_after_imputation) > 0) {
  # Apply MICE imputation again on the combined dataset
  imputed <- mice(imputed_data, m = 5, method = 'pmm', seed = 998, printFlag = FALSE)
  imputed_data <- complete(imputed)
  # Remove intermediate MICE object
  rm(imputed)
}

# Check again for any remaining NAs in the dataset
na_columns_final_check <- sapply(imputed_data, function(x) sum(is.na(x)))
na_columns_final_check <- na_columns_final_check[na_columns_final_check > 0]

# Print the columns with remaining NA values (if any) and the number of NA values in each
print(na_columns_final_check)

# Complete the dataset
data_prepost_cat_clean <- imputed_data

# Remove the final imputed data frame to clean up environment
rm(imputed_data, na_columns_final_check, imputed_data_list, na_columns_after_imputation)

```

Save imputed data frame.

```{r save imputed data cat, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
write.csv(data_prepost_cat_clean, file = paste0(datasets, "catDataXGB.csv"), row.names = FALSE)
```

### XGBoost

Ensure parallel processing.

```{r parallel cat, echo=TRUE, message=FALSE, warning=FALSE}
# Detect the number of available cores
cores <- detectCores() #- 1  # Leave one core free

# Create a cluster with the detected number of cores
cl <- makeCluster(cores)

# Register the parallel backend
registerDoParallel(cl)
```

Define the grid and estimate runtime.

```{r grid cat, echo=TRUE, message=FALSE, warning=FALSE}
grid_tune <- expand.grid(
  nrounds = c(5000, 10000), 
  max_depth = c(3, 6), 
  eta = c(0.05, 0.1), 
  gamma = c(0.1), 
  colsample_bytree = c(0.6, 0.8), 
  min_child_weight = c(1), 
  subsample = c(0.75, 1.0)
)

# Calculate total combinations
total_combinations <- nrow(grid_tune)

# Estimate single model run time (assume 1 minute per run)
single_model_time <- 10 # minute

# Total runs for cross-validation
folds <- 5
total_runs <- total_combinations * folds

# Total time estimation without parallel processing
total_time <- total_runs * single_model_time # in minutes

# Convert to hours
total_time_hours <- total_time / 60

# Output estimated time without parallel processing
print(paste("Estimated time for grid search without parallel processing:", total_time_hours, "hours"))

# Parallel processing with 4 cores
cores <- 24
total_time_parallel <- total_time / cores # in minutes

# Convert to hours
total_time_parallel_hours <- total_time_parallel / 60

# Output estimated time with parallel processing
print(paste("Estimated time for grid search with", cores, "cores:", total_time_parallel_hours, "hours"))

rm(total_combinations,single_model_time,folds,total_runs,total_time,total_time_hours,total_time_parallel,total_time_parallel_hours,cores)
```

#### K-fold cross-validation

Create subsets to train and test data (80/20).

```{r k-fold subset cat, echo=TRUE, message=FALSE, warning=FALSE}
# Set seed for reproducibility
set.seed(998)

# Set up train control
train_control <- trainControl(
  method = "cv",        # Cross-validation
  number = 5,           # 5-fold cross-validation
  allowParallel = TRUE  # Enable parallel processing
)

# Define the number of subsets
numSubsets <- 5

# Create an empty list to store subsets
catSubsets <- vector("list", length = numSubsets)

# load MICE imputed data
catDataXGB <- read_csv(paste0(datasets, "catDataXGB.csv"))
# ensure percProm is factor
catDataXGB$percProm <- as.factor(catDataXGB$percProm)
levels(catDataXGB$percProm)
# only keep the columns of output and predictor variables
catDataXGB <- catDataXGB[,13:97] 

# Calculate the number of samples in each subset
subsetSize <- nrow(catDataXGB) %/% numSubsets

# Randomly assign samples to subsets
for (i in 1:numSubsets) {
  if (i < numSubsets) {
    catSubsets[[i]] <- catDataXGB[sample((1:nrow(catDataXGB)), size = subsetSize), ]
  } else {
    catSubsets[[i]] <- catDataXGB[sample((1:nrow(catDataXGB)), size = subsetSize + (nrow(catDataXGB) %% numSubsets)), ]
  }
}

# Naming the subsets
names(catSubsets) <- paste0("catData", 1:numSubsets)

# Access the subsets (e.g., catData1, catData2, etc.)
catData1 <- catSubsets$catData1
catData2 <- catSubsets$catData2
catData3 <- catSubsets$catData3
catData4 <- catSubsets$catData4
catData5 <- catSubsets$catData5

# Combine subsets into 80% groups.
catData1234 <- rbind(catData1, catData2, catData3, catData4)
catData1235 <- rbind(catData1, catData2, catData3, catData5)
catData1245 <- rbind(catData1, catData2, catData4, catData5)
catData1345 <- rbind(catData1, catData3, catData4, catData5)
catData2345 <- rbind(catData2, catData3, catData4, catData5)

```

#### Models

Only run the models one time and then readRDS.

##### Model 1

```{r cat model1, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
catModel1 <- caret::train(
  percProm ~ .,              
  data = catData1234,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(catModel1, file = paste0(models, "catModel1.rds"), compress = TRUE)
```

##### Model 2

```{r cat model2, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
catModel2 <- caret::train(
  percProm ~ .,              
  data = catData1235,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(catModel2, file = paste0(models, "catModel2.rds"), compress = TRUE)
```

##### Model 3

```{r cat model3, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
catModel3 <- caret::train(
  percProm ~ .,              
  data = catData1245,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(catModel3, file = paste0(models, "catModel3.rds"), compress = TRUE)
```

##### Model 4

```{r cat model4, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
catModel4 <- caret::train(
  percProm ~ .,              
  data = catData1345,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)
saveRDS(catModel4, file = paste0(models, "catModel4.rds"), compress = TRUE)
```

##### Model 5

```{r cat model5, echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE}
catModel5 <- caret::train(
  percProm ~ .,              
  data = catData2345,
  method = "xgbTree",     
  trControl = train_control,
  tuneGrid = grid_tune    
)

saveRDS(catModel5, file = paste0(models, "catModel5.rds"), compress = TRUE)
```

##### Load models

Load all models after running, if necessary.

```{r load models cat, echo=TRUE, message=FALSE, warning=FALSE}
catModel1 <- readRDS(paste0(models, "catModel1.rds"))
catModel2 <- readRDS(paste0(models, "catModel2.rds"))
catModel3 <- readRDS(paste0(models, "catModel3.rds"))
catModel4 <- readRDS(paste0(models, "catModel4.rds"))
catModel5 <- readRDS(paste0(models, "catModel5.rds"))
```

#### Test models

Generate predictions and confusion matrices

```{r test models cat, echo=TRUE, message=FALSE, warning=FALSE}
# Generate predictions
catPredictions1 <- predict(catModel1, newdata = catData5)
catPredictions2 <- predict(catModel2, newdata = catData4)
catPredictions3 <- predict(catModel3, newdata = catData3)
catPredictions4 <- predict(catModel4, newdata = catData2)
catPredictions5 <- predict(catModel5, newdata = catData1)

# Compute confusion matrices
catCm1 <- confusionMatrix(catPredictions1, catData5$percProm)
catCm2 <- confusionMatrix(catPredictions2, catData4$percProm)
catCm3 <- confusionMatrix(catPredictions3, catData3$percProm)
catCm4 <- confusionMatrix(catPredictions4, catData2$percProm)
catCm5 <- confusionMatrix(catPredictions5, catData1$percProm)

# Extract p-values (you need to define how to extract these based on your metric, here assumed to be some metric from confusion matrix)
catPValues <- c(catCm1$overall['AccuracyPValue'], 
              catCm2$overall['AccuracyPValue'], 
              catCm3$overall['AccuracyPValue'], 
              catCm4$overall['AccuracyPValue'], 
              catCm5$overall['AccuracyPValue'])
```

Show confusion matrices.

```{r output cat, echo=TRUE, message=FALSE, warning=FALSE}
catCm1
catCm2
catCm3
catCm4
catCm5
```

Combine p-values using Fisher's method

```{r combine p-vals cat, echo=TRUE, message=FALSE, warning=FALSE}
# Fisher's method
catFisher_combined <- -2 * sum(log(catPValues))
df <- 2 * length(catPValues)
catPCcombined_fisher <- 1 - pchisq(catFisher_combined, df)
print(catPCcombined_fisher)

# Stouffer's method
catZ_scores <- qnorm(1 - catPValues/2)
catCombined_z <- sum(catZ_scores) / sqrt(length(catPValues))
catP_combined_stouffer <- 2 * (1 - pnorm(abs(catCombined_z)))
print(catP_combined_stouffer)
```

The p-values sum up to 0, since they are all so small.

#### Feature importance

##### Model 1

```{r cat feature importance 1, echo=TRUE, message=FALSE, warning=FALSE}
XGBcatModel1 <- catModel1$finalModel
importanceXGBcatModel1 <- xgb.importance(model = XGBcatModel1)
print(importanceXGBcatModel1)
xgb.plot.importance(importanceXGBcatModel1[1:10,])
```

##### Model 2

```{r cat feature importance 2, echo=TRUE, message=FALSE, warning=FALSE}
XGBcatModel2 <- catModel2$finalModel
importanceXGBcatModel2 <- xgb.importance(model = XGBcatModel2)
print(importanceXGBcatModel2)
xgb.plot.importance(importanceXGBcatModel2[1:10,])
```

##### Model 3

```{r cat feature importance 3, echo=TRUE, message=FALSE, warning=FALSE}
XGBcatModel3 <- catModel3$finalModel
importanceXGBcatModel3 <- xgb.importance(model = XGBcatModel3)
print(importanceXGBcatModel3)
xgb.plot.importance(importanceXGBcatModel3[1:10,])
```

##### Model 4

```{r cat feature importance 4, echo=TRUE, message=FALSE, warning=FALSE}
XGBcatModel4 <- catModel4$finalModel
importanceXGBcatModel4 <- xgb.importance(model = XGBcatModel4)
print(importanceXGBcatModel4)
xgb.plot.importance(importanceXGBcatModel4[1:10,])
```

##### Model 5

```{r cat feature importance 5, echo=TRUE, message=FALSE, warning=FALSE}
XGBcatModel5 <- catModel5$finalModel
importanceXGBcatModel5 <- xgb.importance(model = XGBcatModel5)
print(importanceXGBcatModel5)
xgb.plot.importance(importanceXGBcatModel5[1:10,])
```

##### Cumulative feature importance

```{r cat cumulative importance, echo=TRUE, message=FALSE, warning=FALSE}
# Function to extract and normalize importance
get_normalized_importance <- function(model) {
  importance <- xgb.importance(model = model)
  importance$Gain <- importance$Gain / sum(importance$Gain)
  return(importance)
}

# Extract normalized importance for each model
catImportance1 <- get_normalized_importance(catModel1$finalModel)
catImportance2 <- get_normalized_importance(catModel2$finalModel)
catImportance3 <- get_normalized_importance(catModel3$finalModel)
catImportance4 <- get_normalized_importance(catModel4$finalModel)
catImportance5 <- get_normalized_importance(catModel5$finalModel)

# Combine importances
catAllImportances <- list(catImportance1, catImportance2, catImportance3, catImportance4, catImportance5)

# Function to merge importances
merge_importances <- function(importances) {
  for (i in 2:length(importances)) {
    names(importances[[i]])[2:4] <- paste0(names(importances[[i]])[2:4], "_", i)
  }
  merged <- Reduce(function(x, y) merge(x, y, by = "Feature", all = TRUE), importances)
  merged[is.na(merged)] <- 0  # Replace NAs with 0
  gain_cols <- grep("Gain", colnames(merged), value = TRUE)
  merged$Cumulative <- rowSums(merged[, ..gain_cols])
  return(merged[, .(Feature, Cumulative)])
}

# Merge and sort importances
catCumulativeImportance <- merge_importances(catAllImportances)
catCumulativeImportance <- catCumulativeImportance[order(-catCumulativeImportance$Cumulative), ]

# Print cumulative feature importance
print(catCumulativeImportance)
```






